{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import things needed for Tensorflow and CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary\n",
    "\n",
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "import tfcoreml\n",
    "import configuration\n",
    "from coremltools.proto import NeuralNetwork_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "# Turn on debugging on error\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the models\n",
    "\n",
    "Create the Tensorflow model and strip all unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = './trainlogIncNEW/model.ckpt'\n",
    "pre_frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "\n",
    "# Which nodes we want to input for the network\n",
    "# Use ['image_feed'] for just Memeception\n",
    "input_node_names = ['seq_embeddings','lstm/state_feed']\n",
    "\n",
    "# Which nodes we want to output from the network\n",
    "# Use ['lstm/initial_state'] for just Memeception\n",
    "output_node_names = ['softmax','lstm/state']\n",
    "\n",
    "# Set the depth of the beam search\n",
    "beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/concat:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "FIRST (1, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd:0' shape=(1, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(2, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/Squeeze_8:0\", shape=(2, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'lstm/basic_lstm_cell/transpose:0' shape=(812, 2) dtype=float32>, 'axis': 1}\n",
      "2\n",
      "(1, 812)\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/transpose_1:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/transpose_2:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "('MULS', [<tf.Tensor 'lstm/basic_lstm_cell/MatMul_1:0' shape=(1, 2048) dtype=float32>, <tf.Tensor 'lstm/basic_lstm_cell/MatMul_2:0' shape=(1, 2048) dtype=float32>])\n",
      "SECOND (2, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd_1:0' shape=(2, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/out SPLITTING\n",
      "splitting mat mul\n",
      "(1, 2, 512)\n",
      "Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'logits/transpose:0' shape=(512, 2) dtype=float32>, 'axis': 1}\n",
      "2\n",
      "(1, 512)\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/transpose_1:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/transpose_2:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n",
      "('MULS', [<tf.Tensor 'logits/MatMul:0' shape=(1, 38521) dtype=float32>, <tf.Tensor 'logits/MatMul_1:0' shape=(1, 38521) dtype=float32>])\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                               checkpoint_file)\n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47091803"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the graph\n",
    "\n",
    "tf_model_path = './log/pre_graph_textgenNEW.pb'\n",
    "tf.train.write_graph(\n",
    "    g,\n",
    "    './log',\n",
    "    'pre_graph_textgenNEW.pb',\n",
    "    as_text=False,\n",
    ")\n",
    "\n",
    "with open(tf_model_path, 'rb') as f:\n",
    "    serialized = f.read()\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip unused graph elements and serialize the output to file\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = original_gdef,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "# Save it to an output file\n",
    "with gfile.GFile(pre_frozen_model_file, 'wb') as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph with checkpoint data inside\n",
    "\n",
    "freeze_graph(input_graph=pre_frozen_model_file,\n",
    "             input_saver='',\n",
    "             input_binary=True,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=','.join(output_node_names),\n",
    "             restore_op_name='save/restore_all',\n",
    "             filename_tensor_name='save/Const:0',\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the model\n",
    "\n",
    "Check that it is producing legit captions for *One does not simply*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and load the vocab\n",
    "\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "vocab_file ='vocab4.txt'\n",
    "vocab = vocabulary.Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "create the universe forgets to write the entire story\n",
      "create the universe forgets to write the entire life\n",
      "creates a sith universe in the future for a reason ?\n",
      "creates a sith universe in the future for a reason who knows\n",
      "oh , you think you're a victim ? that's cute .\n",
      "i dont always go to church but when i do , i make sure to become a lawyer\n",
      "i dont always go to church but when i do , i make sure to be the best\n",
      "i am not amused\n",
      "i am not your father\n",
      "i can kill a mockingbird\n",
      "i can kill everyone !\n",
      "says he will never be able to get to save the world . . .\n",
      "says he will never be able to get to save the world . .\n",
      "created the universe except the world !\n",
      "created the universe except to take the entire bible\n",
      "creates thousands of human race creates everyone\n",
      "creates thousands of human race creates the universe to the universe\n",
      "sees your mother in the woods decides to have sex\n",
      "sees your mother in the woods decides to be home\n",
      "i am not an archaeologist\n",
      "loves you all the time of sins\n",
      "loves you all the time of others gets offended\n",
      "gets a million dollars makes a video about a new meme\n",
      "gets a million dollars makes a video about a new world ending\n",
      "tells you you are going to wear a shirt he doesn't want to look in the head\n",
      "create a good holiday\n",
      "create a good work ? no problem . i am a nursing major\n",
      "creates universe to prove his name in the most powerful meme\n",
      "creates universe to prove his name in the most powerful meme and laughs .\n",
      "i was an a zombie but then i took an arrow to the knee\n",
      "i was an a zombie but then i took an arrow in the knee\n",
      "i used to be an adventurer like you but then i used to do\n",
      "i used to be an adventurer like you but then i used to be a true\n",
      "makes a good time makes a meme about himself\n",
      "makes a good time makes a meme about cancer and disease\n",
      "gives you the ability to help people not\n",
      "gives you the ability to help people not believe it\n",
      "why are you fucking serious ?\n",
      "why are you fucking serious\n",
      "creates the universe to sin\n",
      "creates the universe to save earth forces them and die .\n",
      "create new universe in the middle of the world . . . is the most talented\n",
      "i got 99 problems , and invalid\n",
      "i got 99 problems , i'm a one\n",
      "no one does not want to hear you all you know is a democracy for you\n",
      "no one does not want to hear you all you know is a democracy for you !\n",
      "the world is near you with the moon\n",
      "the world is near you with the dead child\n",
      "oh , my god is wrong\n",
      "oh , my god is so rich\n",
      "has faith in humanity creates one person on earth\n",
      "has faith in humanity creates one person to get the first\n",
      "creates your own religion with pride\n",
      "creates your own religion with gays thinks you're christian\n",
      "oh , i'll just believe that one in your country is responsible for your actions\n",
      "god doesn't exist\n",
      "god doesn't exist ? don't care .\n",
      "the end of the world is not enough of all the jews\n",
      "the end of the world is not enough of it when you get into your head !\n",
      "gives you a few bucks for a month ? ? no , i dont care\n",
      "religion is a sin is a god of love and tolerance\n",
      "religion is a sin is a god of love and tolerance makes a religion of christians\n",
      "thou shalt not kill thy children !\n",
      "thou shalt not kill thy art thou shalt not pass\n",
      "created a war with people\n",
      "created a war with people who killed us for a whole time ?\n",
      "takes over an arrow in the knee while you can do it\n",
      "takes over an arrow in the knee ? i'm the only one that can do\n",
      "you will have to get a bunch of my kids\n",
      "you will have to get a bunch of my kids now , do you even\n",
      "get the fuck up !\n",
      "get the fuck back\n",
      "the awkward moment when you complain that you are not giving a job you should feel bad\n",
      "the awkward moment when you complain that you are not giving a job you should have a\n",
      "tells you to be like a kid wants to be your brother\n",
      "tells you to be like a kid wants to be your sister\n",
      "gives a blowjob for christmas doesn't think you do\n",
      "gives a blowjob for christmas doesn't think you are a sin\n",
      "gets rejected by one day\n",
      "gets rejected by one more than 5 years\n",
      "creates the universe to become a christian creates a universe\n",
      "creates the universe to become an atheist everyone thinks you're gay\n",
      "creates bible as a meme in your country\n",
      "creates bible as a meme in your country and asks you for 10 minutes\n",
      "goes to the store , and the only prescription\n",
      "goes to church church with ex and a pedophile on twitter\n",
      "i have a problem with my religion\n",
      "i have a problem with my memes\n",
      "hey , i just met you , and this is crazy . . but i want to be\n",
      "hey , i just met you , and this is crazy . . but i want to be\n",
      "thou shalt not pass !\n",
      "thou shalt not pass ! i am the law !\n",
      "thou shalt not forgive this shit\n",
      "thou shalt not forgive my father i like to go to the dark side\n"
     ]
    }
   ],
   "source": [
    "# Generate captions on a hard-coded image\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "  restore_fn(sess)\n",
    "  generator = caption_generator.CaptionGenerator(\n",
    "      model, vocab, beam_size=beam_size)\n",
    "  for i,filename in enumerate(['memes/advice-god.jpg']):\n",
    "    with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "      image = Image.open(f)\n",
    "      image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0\n",
    "    for k in range(50):\n",
    "      captions = generator.beam_search(sess, image)    \n",
    "      for i, caption in enumerate(captions):\n",
    "        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "        sentence = \" \".join(sentence)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to CoreML\n",
    "\n",
    "Specify output variables from the graph to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic shapes\n",
    "# If using Memeception, add 'image_feed:0': [299, 299, 3]\n",
    "input_tensor_shapes = {\n",
    "    'seq_embeddings:0': [1, beam_size, 300],\n",
    "    'lstm/state_feed:0': [1, beam_size, 1024],\n",
    "}\n",
    "\n",
    "coreml_model_file = './Textgen_NEW.mlmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor_names = [node + ':0' for node in output_node_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 90 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob lstm/state_feed:0\n",
      "1/146: Analysing op name: seq_embeddings ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "2/146: Analysing op name: lstm/basic_lstm_cell/kernel ( type:  Const )\n",
      "3/146: Analysing op name: lstm/basic_lstm_cell/kernel/read ( type:  Identity )\n",
      "4/146: Analysing op name: lstm/basic_lstm_cell/bias ( type:  Const )\n",
      "5/146: Analysing op name: lstm/basic_lstm_cell/bias/read ( type:  Identity )\n",
      "6/146: Analysing op name: lstm/state_feed ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/146: Analysing op name: lstm/ExpandDims/dim ( type:  Const )\n",
      "8/146: Analysing op name: lstm/ExpandDims ( type:  ExpandDims )\n",
      "9/146: Analysing op name: lstm/split/split_dim ( type:  Const )\n",
      "10/146: Analysing op name: lstm/split ( type:  Split )\n",
      "11/146: Analysing op name: lstm/Squeeze ( type:  Squeeze )\n",
      "12/146: Analysing op name: lstm/Squeeze_1 ( type:  Squeeze )\n",
      "13/146: Analysing op name: lstm/basic_lstm_cell/concat_1/axis ( type:  Const )\n",
      "14/146: Analysing op name: lstm/basic_lstm_cell/concat_1 ( type:  ConcatV2 )\n",
      "15/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_8 ( type:  Squeeze )\n",
      "16/146: Analysing op name: lstm/basic_lstm_cell/transpose/Rank ( type:  Rank )\n",
      "17/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub/y ( type:  Const )\n",
      "18/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub ( type:  Sub )\n",
      "19/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range/start ( type:  Const )\n",
      "20/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range/delta ( type:  Const )\n",
      "21/146: Analysing op name: lstm/basic_lstm_cell/transpose/Range ( type:  Range )\n",
      "22/146: Analysing op name: lstm/basic_lstm_cell/transpose/sub_1 ( type:  Sub )\n",
      "23/146: Analysing op name: lstm/basic_lstm_cell/transpose ( type:  Transpose )\n",
      "24/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2/dim ( type:  Const )\n",
      "25/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2 ( type:  ExpandDims )\n",
      "26/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3/dim ( type:  Const )\n",
      "27/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3 ( type:  ExpandDims )\n",
      "28/146: Analysing op name: lstm/basic_lstm_cell/split_1/split_dim ( type:  Const )\n",
      "29/146: Analysing op name: lstm/basic_lstm_cell/split_1 ( type:  Split )\n",
      "30/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_9 ( type:  Squeeze )\n",
      "31/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_10 ( type:  Squeeze )\n",
      "32/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Rank ( type:  Rank )\n",
      "33/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_11 ( type:  Squeeze )\n",
      "34/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_12 ( type:  Squeeze )\n",
      "35/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Rank ( type:  Rank )\n",
      "36/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub/y ( type:  Const )\n",
      "37/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub ( type:  Sub )\n",
      "38/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/start ( type:  Const )\n",
      "39/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range/delta ( type:  Const )\n",
      "40/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/Range ( type:  Range )\n",
      "41/146: Analysing op name: lstm/basic_lstm_cell/transpose_1/sub_1 ( type:  Sub )\n",
      "42/146: Analysing op name: lstm/basic_lstm_cell/transpose_1 ( type:  Transpose )\n",
      "43/146: Analysing op name: lstm/basic_lstm_cell/MatMul_1 ( type:  MatMul )\n",
      "44/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub/y ( type:  Const )\n",
      "45/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub ( type:  Sub )\n",
      "46/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/start ( type:  Const )\n",
      "47/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range/delta ( type:  Const )\n",
      "48/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/Range ( type:  Range )\n",
      "49/146: Analysing op name: lstm/basic_lstm_cell/transpose_2/sub_1 ( type:  Sub )\n",
      "50/146: Analysing op name: lstm/basic_lstm_cell/transpose_2 ( type:  Transpose )\n",
      "51/146: Analysing op name: lstm/basic_lstm_cell/MatMul_2 ( type:  MatMul )\n",
      "52/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4/dim ( type:  Const )\n",
      "53/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4 ( type:  ExpandDims )\n",
      "54/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5/dim ( type:  Const )\n",
      "55/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5 ( type:  ExpandDims )\n",
      "56/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6/dim ( type:  Const )\n",
      "57/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_6 ( type:  ExpandDims )\n",
      "58/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7/dim ( type:  Const )\n",
      "59/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_7 ( type:  ExpandDims )\n",
      "60/146: Analysing op name: lstm/basic_lstm_cell/concat_2/axis ( type:  Const )\n",
      "61/146: Analysing op name: lstm/basic_lstm_cell/concat_2 ( type:  ConcatV2 )\n",
      "62/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_13 ( type:  Squeeze )\n",
      "63/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_14 ( type:  Squeeze )\n",
      "64/146: Analysing op name: lstm/basic_lstm_cell/BiasAdd_1 ( type:  BiasAdd )\n",
      "65/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8/dim ( type:  Const )\n",
      "66/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_8 ( type:  ExpandDims )\n",
      "67/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9/dim ( type:  Const )\n",
      "68/146: Analysing op name: lstm/basic_lstm_cell/ExpandDims_9 ( type:  ExpandDims )\n",
      "69/146: Analysing op name: lstm/basic_lstm_cell/split_2/split_dim ( type:  Const )\n",
      "70/146: Analysing op name: lstm/basic_lstm_cell/split_2 ( type:  Split )\n",
      "71/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_15 ( type:  Squeeze )\n",
      "72/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_16 ( type:  Squeeze )\n",
      "73/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_4 ( type:  Sigmoid )\n",
      "74/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_17 ( type:  Squeeze )\n",
      "75/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_18 ( type:  Squeeze )\n",
      "76/146: Analysing op name: lstm/basic_lstm_cell/Tanh_2 ( type:  Tanh )\n",
      "77/146: Analysing op name: lstm/basic_lstm_cell/Mul_4 ( type:  Mul )\n",
      "78/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_19 ( type:  Squeeze )\n",
      "79/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_20 ( type:  Squeeze )\n",
      "80/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_21 ( type:  Squeeze )\n",
      "81/146: Analysing op name: lstm/basic_lstm_cell/Squeeze_22 ( type:  Squeeze )\n",
      "82/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_5 ( type:  Sigmoid )\n",
      "83/146: Analysing op name: lstm/basic_lstm_cell/Const_4 ( type:  Const )\n",
      "84/146: Analysing op name: lstm/basic_lstm_cell/Add_2 ( type:  Add )\n",
      "85/146: Analysing op name: lstm/basic_lstm_cell/Sigmoid_3 ( type:  Sigmoid )\n",
      "86/146: Analysing op name: lstm/basic_lstm_cell/Mul_3 ( type:  Mul )\n",
      "87/146: Analysing op name: lstm/basic_lstm_cell/Add_3 ( type:  Add )\n",
      "88/146: Analysing op name: lstm/basic_lstm_cell/Tanh_3 ( type:  Tanh )\n",
      "89/146: Analysing op name: lstm/basic_lstm_cell/Mul_5 ( type:  Mul )\n",
      "90/146: Analysing op name: logits/Squeeze ( type:  Squeeze )\n",
      "91/146: Analysing op name: logits/transpose/Rank ( type:  Rank )\n",
      "92/146: Analysing op name: lstm/state/axis ( type:  Const )\n",
      "93/146: Analysing op name: lstm/state ( type:  ConcatV2 )\n",
      "94/146: Analysing op name: logits/weights ( type:  Const )\n",
      "95/146: Analysing op name: logits/weights/read ( type:  Identity )\n",
      "96/146: Analysing op name: logits/biases ( type:  Const )\n",
      "97/146: Analysing op name: logits/biases/read ( type:  Identity )\n",
      "98/146: Analysing op name: logits/transpose/sub/y ( type:  Const )\n",
      "99/146: Analysing op name: logits/transpose/sub ( type:  Sub )\n",
      "100/146: Analysing op name: logits/transpose/Range/start ( type:  Const )\n",
      "101/146: Analysing op name: logits/transpose/Range/delta ( type:  Const )\n",
      "102/146: Analysing op name: logits/transpose/Range ( type:  Range )\n",
      "103/146: Analysing op name: logits/transpose/sub_1 ( type:  Sub )\n",
      "104/146: Analysing op name: logits/transpose ( type:  Transpose )\n",
      "105/146: Analysing op name: logits/ExpandDims/dim ( type:  Const )\n",
      "106/146: Analysing op name: logits/ExpandDims ( type:  ExpandDims )\n",
      "107/146: Analysing op name: logits/ExpandDims_1/dim ( type:  Const )\n",
      "108/146: Analysing op name: logits/ExpandDims_1 ( type:  ExpandDims )\n",
      "109/146: Analysing op name: logits/split/split_dim ( type:  Const )\n",
      "110/146: Analysing op name: logits/split ( type:  Split )\n",
      "111/146: Analysing op name: logits/Squeeze_1 ( type:  Squeeze )\n",
      "112/146: Analysing op name: logits/Squeeze_2 ( type:  Squeeze )\n",
      "113/146: Analysing op name: logits/transpose_1/Rank ( type:  Rank )\n",
      "114/146: Analysing op name: logits/Squeeze_3 ( type:  Squeeze )\n",
      "115/146: Analysing op name: logits/Squeeze_4 ( type:  Squeeze )\n",
      "116/146: Analysing op name: logits/transpose_2/Rank ( type:  Rank )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/146: Analysing op name: logits/transpose_1/sub/y ( type:  Const )\n",
      "118/146: Analysing op name: logits/transpose_1/sub ( type:  Sub )\n",
      "119/146: Analysing op name: logits/transpose_1/Range/start ( type:  Const )\n",
      "120/146: Analysing op name: logits/transpose_1/Range/delta ( type:  Const )\n",
      "121/146: Analysing op name: logits/transpose_1/Range ( type:  Range )\n",
      "122/146: Analysing op name: logits/transpose_1/sub_1 ( type:  Sub )\n",
      "123/146: Analysing op name: logits/transpose_1 ( type:  Transpose )\n",
      "124/146: Analysing op name: logits/MatMul ( type:  MatMul )\n",
      "125/146: Analysing op name: logits/transpose_2/sub/y ( type:  Const )\n",
      "126/146: Analysing op name: logits/transpose_2/sub ( type:  Sub )\n",
      "127/146: Analysing op name: logits/transpose_2/Range/start ( type:  Const )\n",
      "128/146: Analysing op name: logits/transpose_2/Range/delta ( type:  Const )\n",
      "129/146: Analysing op name: logits/transpose_2/Range ( type:  Range )\n",
      "130/146: Analysing op name: logits/transpose_2/sub_1 ( type:  Sub )\n",
      "131/146: Analysing op name: logits/transpose_2 ( type:  Transpose )\n",
      "132/146: Analysing op name: logits/MatMul_1 ( type:  MatMul )\n",
      "133/146: Analysing op name: logits/ExpandDims_2/dim ( type:  Const )\n",
      "134/146: Analysing op name: logits/ExpandDims_2 ( type:  ExpandDims )\n",
      "135/146: Analysing op name: logits/ExpandDims_3/dim ( type:  Const )\n",
      "136/146: Analysing op name: logits/ExpandDims_3 ( type:  ExpandDims )\n",
      "137/146: Analysing op name: logits/ExpandDims_4/dim ( type:  Const )\n",
      "138/146: Analysing op name: logits/ExpandDims_4 ( type:  ExpandDims )\n",
      "139/146: Analysing op name: logits/ExpandDims_5/dim ( type:  Const )\n",
      "140/146: Analysing op name: logits/ExpandDims_5 ( type:  ExpandDims )\n",
      "141/146: Analysing op name: logits/concat/axis ( type:  Const )\n",
      "142/146: Analysing op name: logits/concat ( type:  ConcatV2 )\n",
      "143/146: Analysing op name: logits/Squeeze_5 ( type:  Squeeze )\n",
      "144/146: Analysing op name: logits/Squeeze_6 ( type:  Squeeze )\n",
      "145/146: Analysing op name: logits/BiasAdd ( type:  BiasAdd )\n",
      "146/146: Analysing op name: softmax ( type:  Softmax )\n",
      "\n",
      " Core ML model generated. Saved at location: ./Textgen_NEW.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"seq_embeddings__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 300\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"lstm__state_feed__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1024\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"lstm__state__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"softmax__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "        output_feature_names=output_tensor_names,\n",
    "        add_custom_layers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Run a predictable randomly seeded inputs through and see where the disparities are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rand = np.random.rand(300)\n",
    "seq_embeddings_tf = np.array([[seq_rand, seq_rand]])\n",
    "seq_embeddings_ml = np.array([[[sr, sr]] for sr in seq_rand])\n",
    "\n",
    "state_rand = np.random.rand(1024)\n",
    "state_feed_tf = np.array([[state_rand, state_rand]])\n",
    "state_feed_ml = np.array([[[sr, sr]] for sr in state_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm__state__0\n",
      "(1, 1, 1024, 1, 2)\n",
      "[[[[[ 0.33205131  0.33205131]]\n",
      "\n",
      "   [[ 0.75343323  0.75343323]]\n",
      "\n",
      "   [[-0.48625529 -0.48625529]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.02359158  0.02359158]]\n",
      "\n",
      "   [[ 0.01174363  0.01174363]]\n",
      "\n",
      "   [[ 0.76747662  0.76747662]]]]]\n",
      "softmax__0\n",
      "(1, 1, 38521, 1, 2)\n",
      "[[[[[7.28907389e-06 7.28907389e-06]]\n",
      "\n",
      "   [[1.88403286e-03 1.88403286e-03]]\n",
      "\n",
      "   [[5.11268014e-03 5.11268014e-03]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[9.21222009e-03 9.21222009e-03]]\n",
      "\n",
      "   [[7.86807504e-06 7.86807504e-06]]\n",
      "\n",
      "   [[1.70122180e-02 1.70122180e-02]]]]]\n"
     ]
    }
   ],
   "source": [
    "coreml_inputs = {\n",
    "    'seq_embeddings__0': seq_embeddings_ml,\n",
    "    'lstm__state_feed__0': state_feed_ml,\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "# print(coreml_output['lstm__state__0'].shape)\n",
    "# print(coreml_output['softmax__0'].shape)\n",
    "# print(coreml_output['softmax__0'].reshape(38521, 1, 2))\n",
    "# print(coreml_output)\n",
    "def print_ml(ml):\n",
    "    for key in sorted(ml.keys()):\n",
    "        print(key)\n",
    "        print(ml[key].shape)\n",
    "        print(ml[key])\n",
    "print_ml(coreml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "lstm/state:0\n",
      "(1, 2, 1024)\n",
      "[[[ 0.33205152  0.7534331  -0.4862553  ...  0.02359157  0.01174365\n",
      "    0.7674767 ]\n",
      "  [ 0.33205152  0.7534331  -0.4862553  ...  0.02359157  0.01174365\n",
      "    0.7674767 ]]]\n",
      "softmax:0\n",
      "(2, 38521)\n",
      "[[7.2891025e-06 1.8840394e-03 5.1127030e-03 ... 9.2122564e-03\n",
      "  7.8681069e-06 1.7012285e-02]\n",
      " [7.2891025e-06 1.8840394e-03 5.1127030e-03 ... 9.2122564e-03\n",
      "  7.8681069e-06 1.7012285e-02]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    input_names = ['lstm/state:0', 'softmax:0']\n",
    "    output_values = sess.run(\n",
    "        fetches=input_names,\n",
    "        feed_dict={\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed_tf,\n",
    "            \"seq_embeddings:0\": seq_embeddings_tf,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    for (index, value) in sorted(enumerate(input_names), key=lambda x: x[1]):\n",
    "        print(value)\n",
    "        print(output_values[index].shape)\n",
    "        print(output_values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(np.random.rand(1, 20), np.random.rand(20, 45)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 812)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(1, 2, 812)[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
