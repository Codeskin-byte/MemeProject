{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import things needed for Tensorflow and CoreML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary\n",
    "\n",
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "import tfcoreml\n",
    "import configuration\n",
    "from coremltools.proto import NeuralNetwork_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "# Turn on debugging on error\n",
    "%pdb on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the models\n",
    "\n",
    "Create the Tensorflow model and strip all unused nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = './trainlogIncNEW/model.ckpt'\n",
    "pre_frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "\n",
    "# Which nodes we want to input for the network\n",
    "# Use ['image_feed'] for just Memeception\n",
    "input_node_names = ['seq_embeddings','lstm/state_feed']\n",
    "\n",
    "# Which nodes we want to output from the network\n",
    "# Use ['lstm/initial_state'] for just Memeception\n",
    "output_node_names = ['softmax','lstm/state']\n",
    "\n",
    "# Set the depth of the beam search\n",
    "beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/concat:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "FIRST (1, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd:0' shape=(1, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "splitting mat mul\n",
      "(2, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/Squeeze_8:0\", shape=(2, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'lstm/basic_lstm_cell/Squeeze_8:0' shape=(2, 812) dtype=float32>, 'axis': 0}\n",
      "2\n",
      "(1, 812)\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/Squeeze_10:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 812)\n",
      "Tensor(\"lstm/basic_lstm_cell/Squeeze_12:0\", shape=(1, 812), dtype=float32)\n",
      "(812, 2048)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "###\n",
      "SECOND (2, 2048)\n",
      "{'num_or_size_splits': 4, 'value': <tf.Tensor 'lstm/basic_lstm_cell/BiasAdd_1:0' shape=(2, 2048) dtype=float32>, 'axis': 1}\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/out SPLITTING\n",
      "splitting mat mul\n",
      "(1, 2, 512)\n",
      "Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "___\n",
      "('NUMSPLITS', 2)\n",
      "{'num_or_size_splits': 2, 'value': <tf.Tensor 'logits/Squeeze:0' shape=(2, 512) dtype=float32>, 'axis': 0}\n",
      "2\n",
      "(1, 512)\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/Squeeze_2:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n",
      "MATMUL###\n",
      "(1, 512)\n",
      "Tensor(\"logits/Squeeze_4:0\", shape=(1, 512), dtype=float32)\n",
      "(512, 38521)\n",
      "<tf.Variable 'logits/weights:0' shape=(512, 38521) dtype=float32_ref>\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                               checkpoint_file)\n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47087360"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the graph\n",
    "\n",
    "tf_model_path = './log/pre_graph_textgenNEW.pb'\n",
    "tf.train.write_graph(\n",
    "    g,\n",
    "    './log',\n",
    "    'pre_graph_textgenNEW.pb',\n",
    "    as_text=False,\n",
    ")\n",
    "\n",
    "with open(tf_model_path, 'rb') as f:\n",
    "    serialized = f.read()\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip unused graph elements and serialize the output to file\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = original_gdef,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "# Save it to an output file\n",
    "with gfile.GFile(pre_frozen_model_file, 'wb') as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Froze 4 variables.\n",
      "Converted 4 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "# Freeze the graph with checkpoint data inside\n",
    "\n",
    "freeze_graph(input_graph=pre_frozen_model_file,\n",
    "             input_saver='',\n",
    "             input_binary=True,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=','.join(output_node_names),\n",
    "             restore_op_name='save/restore_all',\n",
    "             filename_tensor_name='save/Const:0',\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the model\n",
    "\n",
    "Check that it is producing legit captions for *One does not simply*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "# Configure the model and load the vocab\n",
    "\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "vocab_file ='vocab4.txt'\n",
    "vocab = vocabulary.Vocabulary(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "one does not simply take the top of the head\n",
      "one does not simply take the top of the head to mordor\n",
      "one does not simply go to the toilet\n",
      "one does not simply go to the canteen\n",
      "one does not simply get a letter\n",
      "one does not simply get a straight guy\n",
      "one does not simply put a trojan on his pc\n",
      "one does not simply put a trojan on his head\n",
      "one does not simply walk into mordor at 7\n",
      "one does not simply walk into mordor at the bar\n"
     ]
    }
   ],
   "source": [
    "# Generate captions on a hard-coded image\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "  restore_fn(sess)\n",
    "  generator = caption_generator.CaptionGenerator(\n",
    "      model, vocab, beam_size=beam_size)\n",
    "  for i,filename in enumerate(['memes/one-does-not-simply.jpg']):\n",
    "    with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "      image = Image.open(f)\n",
    "      image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0\n",
    "    for k in range(5):\n",
    "      captions = generator.beam_search(sess, image)    \n",
    "      for i, caption in enumerate(captions):\n",
    "        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "        sentence = \" \".join(sentence)\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model to CoreML\n",
    "\n",
    "Specify output variables from the graph to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic shapes\n",
    "# If using Memeception, add 'image_feed:0': [299, 299, 3]\n",
    "input_tensor_shapes = {\n",
    "    'seq_embeddings:0': [1, beam_size, 300],\n",
    "    'lstm/state_feed:0': [1, beam_size, 1024],\n",
    "}\n",
    "\n",
    "coreml_model_file = './Textgen_NEW.mlmodel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor_names = [node + ':0' for node in output_node_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 69 tensors. Executing graph to determine shapes. \n",
      "Automatic shape interpretation succeeded for input blob lstm/state_feed:0\n",
      "1/107: Analysing op name: seq_embeddings ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "2/107: Analysing op name: lstm/basic_lstm_cell/kernel ( type:  Const )\n",
      "3/107: Analysing op name: lstm/basic_lstm_cell/kernel/read ( type:  Identity )\n",
      "4/107: Analysing op name: lstm/basic_lstm_cell/bias ( type:  Const )\n",
      "5/107: Analysing op name: lstm/basic_lstm_cell/bias/read ( type:  Identity )\n",
      "6/107: Analysing op name: lstm/state_feed ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "7/107: Analysing op name: lstm/ExpandDims/dim ( type:  Const )\n",
      "8/107: Analysing op name: lstm/ExpandDims ( type:  ExpandDims )\n",
      "9/107: Analysing op name: lstm/split/split_dim ( type:  Const )\n",
      "10/107: Analysing op name: lstm/split ( type:  Split )\n",
      "11/107: Analysing op name: lstm/Squeeze ( type:  Squeeze )\n",
      "12/107: Analysing op name: lstm/Squeeze_1 ( type:  Squeeze )\n",
      "13/107: Analysing op name: lstm/basic_lstm_cell/concat_1/axis ( type:  Const )\n",
      "14/107: Analysing op name: lstm/basic_lstm_cell/concat_1 ( type:  ConcatV2 )\n",
      "15/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_8 ( type:  Squeeze )\n",
      "16/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2/dim ( type:  Const )\n",
      "17/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_2 ( type:  ExpandDims )\n",
      "18/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3/dim ( type:  Const )\n",
      "19/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_3 ( type:  ExpandDims )\n",
      "20/107: Analysing op name: lstm/basic_lstm_cell/transpose/perm ( type:  Const )\n",
      "21/107: Analysing op name: lstm/basic_lstm_cell/transpose ( type:  Transpose )\n",
      "22/107: Analysing op name: lstm/basic_lstm_cell/split_1/split_dim ( type:  Const )\n",
      "23/107: Analysing op name: lstm/basic_lstm_cell/split_1 ( type:  Split )\n",
      "24/107: Analysing op name: lstm/basic_lstm_cell/transpose_1/perm ( type:  Const )\n",
      "25/107: Analysing op name: lstm/basic_lstm_cell/transpose_1 ( type:  Transpose )\n",
      "26/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_9 ( type:  Squeeze )\n",
      "27/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_10 ( type:  Squeeze )\n",
      "28/107: Analysing op name: lstm/basic_lstm_cell/MatMul_1 ( type:  MatMul )\n",
      "29/107: Analysing op name: lstm/basic_lstm_cell/transpose_2/perm ( type:  Const )\n",
      "30/107: Analysing op name: lstm/basic_lstm_cell/transpose_2 ( type:  Transpose )\n",
      "31/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_11 ( type:  Squeeze )\n",
      "32/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_12 ( type:  Squeeze )\n",
      "33/107: Analysing op name: lstm/basic_lstm_cell/MatMul_2 ( type:  MatMul )\n",
      "34/107: Analysing op name: lstm/basic_lstm_cell/concat_2/axis ( type:  Const )\n",
      "35/107: Analysing op name: lstm/basic_lstm_cell/concat_2 ( type:  ConcatV2 )\n",
      "36/107: Analysing op name: lstm/basic_lstm_cell/BiasAdd_1 ( type:  BiasAdd )\n",
      "37/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4/dim ( type:  Const )\n",
      "38/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_4 ( type:  ExpandDims )\n",
      "39/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5/dim ( type:  Const )\n",
      "40/107: Analysing op name: lstm/basic_lstm_cell/ExpandDims_5 ( type:  ExpandDims )\n",
      "41/107: Analysing op name: lstm/basic_lstm_cell/split_2/split_dim ( type:  Const )\n",
      "42/107: Analysing op name: lstm/basic_lstm_cell/split_2 ( type:  Split )\n",
      "43/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_13 ( type:  Squeeze )\n",
      "44/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_14 ( type:  Squeeze )\n",
      "45/107: Analysing op name: lstm/basic_lstm_cell/Sigmoid_4 ( type:  Sigmoid )\n",
      "46/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_15 ( type:  Squeeze )\n",
      "47/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_16 ( type:  Squeeze )\n",
      "48/107: Analysing op name: lstm/basic_lstm_cell/Tanh_2 ( type:  Tanh )\n",
      "49/107: Analysing op name: lstm/basic_lstm_cell/Mul_4 ( type:  Mul )\n",
      "50/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_17 ( type:  Squeeze )\n",
      "51/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_18 ( type:  Squeeze )\n",
      "52/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_19 ( type:  Squeeze )\n",
      "53/107: Analysing op name: lstm/basic_lstm_cell/Squeeze_20 ( type:  Squeeze )\n",
      "54/107: Analysing op name: lstm/basic_lstm_cell/Sigmoid_5 ( type:  Sigmoid )\n",
      "55/107: Analysing op name: lstm/basic_lstm_cell/Const_4 ( type:  Const )\n",
      "56/107: Analysing op name: lstm/basic_lstm_cell/Add_2 ( type:  Add )\n",
      "57/107: Analysing op name: lstm/basic_lstm_cell/Sigmoid_3 ( type:  Sigmoid )\n",
      "58/107: Analysing op name: lstm/basic_lstm_cell/Mul_3 ( type:  Mul )\n",
      "59/107: Analysing op name: lstm/basic_lstm_cell/Add_3 ( type:  Add )\n",
      "60/107: Analysing op name: lstm/basic_lstm_cell/Tanh_3 ( type:  Tanh )\n",
      "61/107: Analysing op name: lstm/basic_lstm_cell/Mul_5 ( type:  Mul )\n",
      "62/107: Analysing op name: logits/Squeeze ( type:  Squeeze )\n",
      "63/107: Analysing op name: lstm/state/axis ( type:  Const )\n",
      "64/107: Analysing op name: lstm/state ( type:  ConcatV2 )\n",
      "65/107: Analysing op name: logits/weights ( type:  Const )\n",
      "66/107: Analysing op name: logits/weights/read ( type:  Identity )\n",
      "67/107: Analysing op name: logits/biases ( type:  Const )\n",
      "68/107: Analysing op name: logits/biases/read ( type:  Identity )\n",
      "69/107: Analysing op name: logits/ExpandDims/dim ( type:  Const )\n",
      "70/107: Analysing op name: logits/ExpandDims ( type:  ExpandDims )\n",
      "71/107: Analysing op name: logits/ExpandDims_1/dim ( type:  Const )\n",
      "72/107: Analysing op name: logits/ExpandDims_1 ( type:  ExpandDims )\n",
      "73/107: Analysing op name: logits/transpose/perm ( type:  Const )\n",
      "74/107: Analysing op name: logits/transpose ( type:  Transpose )\n",
      "75/107: Analysing op name: logits/split/split_dim ( type:  Const )\n",
      "76/107: Analysing op name: logits/split ( type:  Split )\n",
      "77/107: Analysing op name: logits/transpose_1/perm ( type:  Const )\n",
      "78/107: Analysing op name: logits/transpose_1 ( type:  Transpose )\n",
      "79/107: Analysing op name: logits/Squeeze_1 ( type:  Squeeze )\n",
      "80/107: Analysing op name: logits/Squeeze_2 ( type:  Squeeze )\n",
      "81/107: Analysing op name: logits/MatMul ( type:  MatMul )\n",
      "82/107: Analysing op name: logits/transpose_2/perm ( type:  Const )\n",
      "83/107: Analysing op name: logits/transpose_2 ( type:  Transpose )\n",
      "84/107: Analysing op name: logits/Squeeze_3 ( type:  Squeeze )\n",
      "85/107: Analysing op name: logits/Squeeze_4 ( type:  Squeeze )\n",
      "86/107: Analysing op name: logits/MatMul_1 ( type:  MatMul )\n",
      "87/107: Analysing op name: logits/ExpandDims_2/dim ( type:  Const )\n",
      "88/107: Analysing op name: logits/ExpandDims_2 ( type:  ExpandDims )\n",
      "89/107: Analysing op name: logits/ExpandDims_3/dim ( type:  Const )\n",
      "90/107: Analysing op name: logits/ExpandDims_3 ( type:  ExpandDims )\n",
      "91/107: Analysing op name: logits/concat/axis ( type:  Const )\n",
      "92/107: Analysing op name: logits/concat ( type:  ConcatV2 )\n",
      "93/107: Analysing op name: logits/BiasAdd ( type:  BiasAdd )\n",
      "94/107: Analysing op name: Shape ( type:  Const )\n",
      "95/107: Analysing op name: Rank ( type:  Const )\n",
      "96/107: Analysing op name: Shape_1 ( type:  Const )\n",
      "97/107: Analysing op name: Sub/y ( type:  Const )\n",
      "98/107: Analysing op name: Sub ( type:  Sub )\n",
      "99/107: Analysing op name: Slice/begin ( type:  Pack )\n",
      "100/107: Analysing op name: Slice/size ( type:  Const )\n",
      "101/107: Analysing op name: Slice ( type:  Slice )\n",
      "102/107: Analysing op name: concat/values_0 ( type:  Const )\n",
      "103/107: Analysing op name: concat/axis ( type:  Const )\n",
      "104/107: Analysing op name: concat ( type:  ConcatV2 )\n",
      "105/107: Analysing op name: Reshape ( type:  Reshape )\n",
      "106/107: Analysing op name: Softmax ( type:  Softmax )\n",
      "107/107: Analysing op name: softmax ( type:  Reshape )\n",
      "\n",
      " Core ML model generated. Saved at location: ./Textgen_NEW.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"seq_embeddings__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 300\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"lstm__state_feed__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1024\n",
      "    shape: 1\n",
      "    shape: 2\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"lstm__state__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"softmax__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "        output_feature_names=output_tensor_names,\n",
    "        add_custom_layers=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Run a predictable randomly seeded inputs through and see where the disparities are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_rand = np.random.rand(300)\n",
    "seq_embeddings_tf = np.array([[seq_rand, seq_rand]])\n",
    "seq_embeddings_ml = np.array([[[sr, sr]] for sr in seq_rand])\n",
    "\n",
    "state_rand = np.random.rand(1024)\n",
    "state_feed_tf = np.array([[state_rand, state_rand]])\n",
    "state_feed_ml = np.array([[[sr, sr]] for sr in state_rand])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm__state__0\n",
      "(812, 1, 1024, 1, 2)\n",
      "[[[[[ 1.28964019  0.9222219 ]]\n",
      "\n",
      "   [[ 1.15617633  0.58406985]]\n",
      "\n",
      "   [[ 0.49004108  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[ 0.05512157 -0.04562627]]\n",
      "\n",
      "   [[ 0.26553747  0.14197578]]\n",
      "\n",
      "   [[ 0.06053435  0.03637091]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.9222219   0.9222219 ]]\n",
      "\n",
      "   [[ 0.58406985  0.58406985]]\n",
      "\n",
      "   [[ 0.16452032  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-0.04562627 -0.04562627]]\n",
      "\n",
      "   [[ 0.14197578  0.14197578]]\n",
      "\n",
      "   [[ 0.03637091  0.03637091]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.9222219   0.9222219 ]]\n",
      "\n",
      "   [[ 0.58406985  0.58406985]]\n",
      "\n",
      "   [[ 0.16452032  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-0.04562627 -0.04562627]]\n",
      "\n",
      "   [[ 0.14197578  0.14197578]]\n",
      "\n",
      "   [[ 0.03637091  0.03637091]]]]\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.9222219   0.9222219 ]]\n",
      "\n",
      "   [[ 0.58406985  0.58406985]]\n",
      "\n",
      "   [[ 0.16452032  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-0.04562627 -0.04562627]]\n",
      "\n",
      "   [[ 0.14197578  0.14197578]]\n",
      "\n",
      "   [[ 0.03637091  0.03637091]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.9222219   0.9222219 ]]\n",
      "\n",
      "   [[ 0.58406985  0.58406985]]\n",
      "\n",
      "   [[ 0.16452032  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-0.04562627 -0.04562627]]\n",
      "\n",
      "   [[ 0.14197578  0.14197578]]\n",
      "\n",
      "   [[ 0.03637091  0.03637091]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.9222219   0.9222219 ]]\n",
      "\n",
      "   [[ 0.58406985  0.58406985]]\n",
      "\n",
      "   [[ 0.16452032  0.16452032]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[-0.04562627 -0.04562627]]\n",
      "\n",
      "   [[ 0.14197578  0.14197578]]\n",
      "\n",
      "   [[ 0.03637091  0.03637091]]]]]\n",
      "softmax__0\n",
      "(512, 1, 38521, 2, 1)\n",
      "[[[[[3.70185512e-06]\n",
      "    [3.68706014e-06]]\n",
      "\n",
      "   [[2.39895540e-03]\n",
      "    [2.38966197e-03]]\n",
      "\n",
      "   [[9.63943079e-03]\n",
      "    [9.64356773e-03]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[2.21076026e-03]\n",
      "    [2.22028373e-03]]\n",
      "\n",
      "   [[5.15237434e-06]\n",
      "    [5.19714422e-06]]\n",
      "\n",
      "   [[5.85676432e-02]\n",
      "    [5.88006824e-02]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[8.19262641e-06]\n",
      "    [8.13929091e-06]]\n",
      "\n",
      "   [[5.59090031e-03]\n",
      "    [5.55554545e-03]]\n",
      "\n",
      "   [[1.36699816e-02]\n",
      "    [1.36732766e-02]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[1.34327039e-02]\n",
      "    [1.35155953e-02]]\n",
      "\n",
      "   [[9.76950378e-06]\n",
      "    [9.89538876e-06]]\n",
      "\n",
      "   [[6.63470626e-02]\n",
      "    [6.67231530e-02]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[1.28664569e-05]\n",
      "    [1.27646781e-05]]\n",
      "\n",
      "   [[9.25361551e-03]\n",
      "    [9.18229390e-03]]\n",
      "\n",
      "   [[1.36954235e-02]\n",
      "    [1.36871450e-02]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[5.89487515e-02]\n",
      "    [5.92915155e-02]]\n",
      "\n",
      "   [[1.31845454e-05]\n",
      "    [1.33570884e-05]]\n",
      "\n",
      "   [[5.30064628e-02]\n",
      "    [5.32858036e-02]]]]\n",
      "\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      "\n",
      " [[[[1.41758028e-05]\n",
      "    [1.41178398e-05]]\n",
      "\n",
      "   [[1.04947099e-02]\n",
      "    [1.04528088e-02]]\n",
      "\n",
      "   [[1.18370224e-02]\n",
      "    [1.18297283e-02]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[1.15098663e-01]\n",
      "    [1.15377769e-01]]\n",
      "\n",
      "   [[1.35254722e-05]\n",
      "    [1.36046910e-05]]\n",
      "\n",
      "   [[4.05927375e-02]\n",
      "    [4.06807140e-02]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[1.12458165e-05]\n",
      "    [1.11958525e-05]]\n",
      "\n",
      "   [[7.92869460e-03]\n",
      "    [7.89440237e-03]]\n",
      "\n",
      "   [[1.42448507e-02]\n",
      "    [1.42422272e-02]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[3.50313857e-02]\n",
      "    [3.51556800e-02]]\n",
      "\n",
      "   [[1.23082527e-05]\n",
      "    [1.24038170e-05]]\n",
      "\n",
      "   [[6.02306426e-02]\n",
      "    [6.04253300e-02]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[1.32503155e-05]\n",
      "    [1.32378955e-05]]\n",
      "\n",
      "   [[9.60315298e-03]\n",
      "    [9.59436689e-03]]\n",
      "\n",
      "   [[1.33143282e-02]\n",
      "    [1.33129479e-02]]\n",
      "\n",
      "   ...\n",
      "\n",
      "   [[7.11756200e-02]\n",
      "    [7.12201446e-02]]\n",
      "\n",
      "   [[1.35390765e-05]\n",
      "    [1.35586615e-05]]\n",
      "\n",
      "   [[5.01553267e-02]\n",
      "    [5.01835905e-02]]]]]\n"
     ]
    }
   ],
   "source": [
    "coreml_inputs = {\n",
    "    'seq_embeddings__0': seq_embeddings_ml,\n",
    "    'lstm__state_feed__0': state_feed_ml,\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "# print(coreml_output['lstm__state__0'].shape)\n",
    "# print(coreml_output['softmax__0'].shape)\n",
    "# print(coreml_output['softmax__0'].reshape(38521, 1, 2))\n",
    "# print(coreml_output)\n",
    "def print_ml(ml):\n",
    "    for key in sorted(ml.keys()):\n",
    "        print(key)\n",
    "        print(ml[key].shape)\n",
    "        print(ml[key])\n",
    "print_ml(coreml_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "lstm/state:0\n",
      "(1, 2, 1024)\n",
      "[[[ 1.1081882   0.13651441 -0.8467241  ...  0.01476664  0.15899816\n",
      "    0.591206  ]\n",
      "  [ 1.1081882   0.13651441 -0.8467241  ...  0.01476664  0.15899816\n",
      "    0.591206  ]]]\n",
      "softmax:0\n",
      "(2, 1, 38521)\n",
      "[[[1.5861393e-05 8.5379388e-03 6.5156026e-03 ... 6.5134992e-03\n",
      "   9.9487688e-06 6.8167374e-02]]\n",
      "\n",
      " [[1.5861393e-05 8.5379388e-03 6.5156026e-03 ... 6.5134992e-03\n",
      "   9.9487688e-06 6.8167374e-02]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    input_names = ['lstm/state:0', 'softmax:0']\n",
    "    output_values = sess.run(\n",
    "        fetches=input_names,\n",
    "        feed_dict={\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed_tf,\n",
    "            \"seq_embeddings:0\": seq_embeddings_tf,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    for (index, value) in sorted(enumerate(input_names), key=lambda x: x[1]):\n",
    "        print(value)\n",
    "        print(output_values[index].shape)\n",
    "        print(output_values[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
