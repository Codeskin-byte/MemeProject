{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "image_dir = os.path.join(current_dir, 'Jmemes')\n",
    "\n",
    "\n",
    "checkpoint_path=\"trainlogIncNEW\"\n",
    "vocab_file =\"vocab4.txt\"\n",
    "input_files =\"Jmemes\"         \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "It's splitting\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/ SPLITTING\n"
     ]
    }
   ],
   "source": [
    "#configuration\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(config,\n",
    "                                               checkpoint_path)\n",
    "g.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.Vocabulary(vocab_file)\n",
    "\n",
    "with open('Captions.txt','r') as f:\n",
    "    data_captions = f.readlines()\n",
    "data_captions = [s.lower() for s in data_captions]\n",
    "  \n",
    "with open('ordered_memes.txt','r') as f:\n",
    "    ordered_memes = f.readlines()\n",
    "ordered_memes = [meme.replace('\\n','') for meme in ordered_memes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/sassy-gay-snape.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/NOSE.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/romneyhood.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/ridiculously-photogenic-metalhead-guy.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/one-does-not-simply.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/sad-dog.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/sudden-realization-ralph.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/y-u-no.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/stoner-stanley.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/stoner-dog.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/advice-dog.jpg']\n",
      "INFO:tensorflow:Running caption generation on 11 files matching Jmemes\n",
      "INFO:tensorflow:Loading model from checkpoint: trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Restoring parameters from trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-1000000\n",
      "Captions for image sassy-gay-snape.jpg:\n",
      "  0) i'm the best (p=0.000004) [in data = 1]\n",
      "  1) i'm the best at all ! (p=0.000000) [in data = 0]\n",
      "  0) i don't always score but when i do i have to finish (p=0.000000) [in data = 0]\n",
      "  1) i don't always score but when i do i have to finish it (p=0.000000) [in data = 0]\n",
      "  0) i love . . . you know . (p=0.000000) [in data = 0]\n",
      "  1) i love . . . you know . . . (p=0.000000) [in data = 0]\n",
      "  0) my name is boxxy i am gay (p=0.000000) [in data = 0]\n",
      "  1) my name is boxxy and im a fag (p=0.000000) [in data = 0]\n",
      "  0) i knew you were gay (p=0.000000) [in data = 1]\n",
      "  1) i knew that i was in a relationship im a baker (p=0.000000) [in data = 0]\n",
      "  0) i was a hipster before i went mainstream (p=0.000000) [in data = 0]\n",
      "  1) i was a hipster before this was cool (p=0.000000) [in data = 0]\n",
      "  0) your name is you and i will kill you (p=0.000000) [in data = 0]\n",
      "  1) your name is you and i need to get (p=0.000000) [in data = 0]\n",
      "  0) yes ! no . . . i did not have a job ! (p=0.000000) [in data = 0]\n",
      "  1) yes ! no . . . i did not have a job ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) i hate my opinion but i love my opinion . (p=0.000000) [in data = 0]\n",
      "  1) i hate my opinion but i love my friends . (p=0.000000) [in data = 0]\n",
      "  0) so you know what you did that . . . (p=0.000000) [in data = 0]\n",
      "  1) so you know what you did that . . (p=0.000000) [in data = 0]\n",
      "number of captions in data = 2\n",
      "Captions for image NOSE.jpg:\n",
      "  0) hi i'm a girl . . . i'll lick my balls ! (p=0.000000) [in data = 0]\n",
      "  1) hi i'm a girl . . . i'll lick my balls . (p=0.000000) [in data = 0]\n",
      "  0) i like you . . . cum (p=0.000000) [in data = 0]\n",
      "  1) i like you . . . too ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) i have a vagina (p=0.000005) [in data = 1]\n",
      "  1) i have a bad time ! (p=0.000000) [in data = 0]\n",
      "  0) i am the most black person on earth (p=0.000000) [in data = 0]\n",
      "  0) i like pussy (p=0.000025) [in data = 1]\n",
      "  1) i like the old ones (p=0.000000) [in data = 0]\n",
      "  0) don't fuck with me ! ! (p=0.000000) [in data = 0]\n",
      "  1) don't fuck with me ! ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) i'm the master of the princess (p=0.000000) [in data = 0]\n",
      "  1) i'm the master of the princess in the world (p=0.000000) [in data = 0]\n",
      "  0) i love u . (p=0.000003) [in data = 1]\n",
      "  1) when you see a tv video show (p=0.000000) [in data = 0]\n",
      "  0) that's right (p=0.000046) [in data = 1]\n",
      "  1) that's my favorite store (p=0.000000) [in data = 0]\n",
      "  0) what's the difference between a girl and a woman ? a boner (p=0.000000) [in data = 0]\n",
      "  1) what's the difference between a girl and a woman ? a bench and a half (p=0.000000) [in data = 0]\n",
      "number of captions in data = 4\n",
      "Captions for image romneyhood.jpg:\n",
      "  0) i like you ! ! ! (p=0.000000) [in data = 0]\n",
      "  1) i like you ! ! (p=0.000000) [in data = 0]\n",
      "  0) you want me ? (p=0.000004) [in data = 0]\n",
      "  1) you want to be funny ? (p=0.000000) [in data = 0]\n",
      "  0) i want to live on you (p=0.000000) [in data = 0]\n",
      "  1) i want to live on you and i will not kill the children in this world (p=0.000000) [in data = 0]\n",
      "  0) my name is james and i like chinese girls (p=0.000000) [in data = 0]\n",
      "  1) my name is james and i like bread but i can eat a potato (p=0.000000) [in data = 0]\n",
      "  0) a mi no me dicen que se acabe la cabeza (p=0.000000) [in data = 0]\n",
      "  1) a mi no me dicen que se van a las de las 7 (p=0.000000) [in data = 0]\n",
      "  0) hey there are you ! ! (p=0.000000) [in data = 0]\n",
      "  1) hey there are you ! ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) i'm a woman i hate you (p=0.000000) [in data = 0]\n",
      "  1) i'm a woman i hate women who i am (p=0.000000) [in data = 0]\n",
      "  0) hi , my name is zoe and this is jackass ! (p=0.000000) [in data = 0]\n",
      "  1) hi , my name is zoe and this is jackass . (p=0.000000) [in data = 0]\n",
      "  0) do you look like a good idea ? because i am not that (p=0.000000) [in data = 0]\n",
      "  1) do you look like a good idea ? because i am not making memes (p=0.000000) [in data = 0]\n",
      "  0) why did i say banana (p=0.000000) [in data = 0]\n",
      "  1) why did i say to the poor in the west (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "Captions for image ridiculously-photogenic-metalhead-guy.jpg:\n",
      "  0) gets invited to his mom she is home (p=0.000000) [in data = 0]\n",
      "  1) gets invited to his mom said she can't sleep (p=0.000000) [in data = 0]\n",
      "  0) plays in the band gets to the left (p=0.000000) [in data = 0]\n",
      "  1) plays in the band gets to go to hell (p=0.000000) [in data = 0]\n",
      "  0) buys a new car gets cancelled (p=0.000000) [in data = 0]\n",
      "  1) i want to be in new meme but i hate it (p=0.000000) [in data = 0]\n",
      "  0) goes to justin bieber concert gets called out the closet (p=0.000000) [in data = 0]\n",
      "  1) goes to justin bieber concert gets called out of his mom (p=0.000000) [in data = 0]\n",
      "  0) has a crush in her pants . . . with her own chest (p=0.000000) [in data = 0]\n",
      "  1) has a crush in her pants . . . with her own chest . (p=0.000000) [in data = 0]\n",
      "  0) gets a tattoo thinks he is a dick (p=0.000000) [in data = 0]\n",
      "  1) gets a tattoo thinks he is a hipster (p=0.000000) [in data = 0]\n",
      "  0) i wish i was cute . (p=0.000000) [in data = 0]\n",
      "  1) i wish i was cute . . . so i can cry like a baby (p=0.000000) [in data = 0]\n",
      "  0) my dick tastes like shit (p=0.000000) [in data = 0]\n",
      "  1) my dick tastes like crap (p=0.000000) [in data = 0]\n",
      "  0) goes to the doctor to get drunk realizes he was hot (p=0.000000) [in data = 0]\n",
      "  1) goes to the doctor to get drunk realizes she was a kid (p=0.000000) [in data = 0]\n",
      "  0) plays bass doesnt have headphones (p=0.000000) [in data = 0]\n",
      "  1) plays bass doesnt have to pee (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "Captions for image one-does-not-simply.jpg:\n",
      "  0) one does not simply say the alphabet of a word . (p=0.000000) [in data = 0]\n",
      "  1) one does not simply say the alphabet of a word . . (p=0.000000) [in data = 0]\n",
      "  0) one does not simply . . . . (p=0.000027) [in data = 0]\n",
      "  1) one does not simply . . . . . (p=0.000012) [in data = 0]\n",
      "  0) one does not simply turn down the volume (p=0.000018) [in data = 0]\n",
      "  1) one does not simply turn down the volume of them (p=0.000000) [in data = 0]\n",
      "  0) one does not simply play an instrument (p=0.000031) [in data = 0]\n",
      "  1) one does not simply play an xbox without being an idiot (p=0.000000) [in data = 0]\n",
      "  0) one does not simply find a meme on facebook (p=0.000009) [in data = 0]\n",
      "  1) one does not simply make a meme about the internet (p=0.000003) [in data = 0]\n",
      "  0) one does not simply eat a burrito without washing hands (p=0.000000) [in data = 0]\n",
      "  1) one does not simply eat pizza with veggies (p=0.000000) [in data = 0]\n",
      "  0) one does not simply have to pee (p=0.000016) [in data = 0]\n",
      "  1) one does not simply have to read the bible right (p=0.000000) [in data = 0]\n",
      "  0) one does not simply jump into a cliff (p=0.000001) [in data = 0]\n",
      "  1) one does not simply jump into a cliff to the tree (p=0.000000) [in data = 0]\n",
      "  0) one does not simply take a song (p=0.000004) [in data = 0]\n",
      "  1) one does not simply take a shit on facebook (p=0.000002) [in data = 0]\n",
      "  0) one does not simply tell a joke about bad luck brian (p=0.000000) [in data = 0]\n",
      "  1) one does not simply tell a joke about bad luck (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "Captions for image sad-dog.jpg:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) you can go to the kitchen (p=0.000000) [in data = 0]\n",
      "  1) you can go to the kitchen not (p=0.000000) [in data = 0]\n",
      "  0) my names sam (p=0.000008) [in data = 1]\n",
      "  1) my names sam ! (p=0.000001) [in data = 0]\n",
      "  0) i wish i was going to make up (p=0.000000) [in data = 0]\n",
      "  1) i wish i was going to find a good guy (p=0.000000) [in data = 0]\n",
      "  0) i am a leaf i dont have to be a good man (p=0.000000) [in data = 0]\n",
      "  1) i am a leaf i dont have to be the best i have (p=0.000000) [in data = 0]\n",
      "  0) i have an appointment and you have a nice day (p=0.000000) [in data = 0]\n",
      "  1) i have an appointment and you have a panic attack (p=0.000000) [in data = 0]\n",
      "  0) what the fuck is this shit ? (p=0.000007) [in data = 0]\n",
      "  1) what the fuck is that (p=0.000008) [in data = 1]\n",
      "  0) you know what i think about cheese . . . . (p=0.000000) [in data = 0]\n",
      "  1) you know what i think about cheese . . . the fuck do you have ? (p=0.000000) [in data = 0]\n",
      "  0) oh my god why the fuck is that shit (p=0.000000) [in data = 0]\n",
      "  1) oh my god why the fuck is she ? (p=0.000000) [in data = 0]\n",
      "  0) this is the right meme (p=0.000000) [in data = 0]\n",
      "  1) hey , can i have a date (p=0.000000) [in data = 0]\n",
      "  0) you know i hate you but i love it (p=0.000000) [in data = 0]\n",
      "  1) you know i hate you but i love pink floyd (p=0.000000) [in data = 0]\n",
      "number of captions in data = 2\n",
      "Captions for image sudden-realization-ralph.jpg:\n",
      "  0) this is the only thing , and if you don't put it on your wall (p=0.000000) [in data = 0]\n",
      "  1) this is the only thing , and if you don't put it on your skin (p=0.000000) [in data = 0]\n",
      "  0) the mayans are the only 99 % and when it is not into a nation (p=0.000000) [in data = 0]\n",
      "  0) if we are out of them in a fucking relationship with no reason why did you get that (p=0.000000) [in data = 0]\n",
      "  1) if we are out of them in a fucking relationship with no reason why do they say no (p=0.000000) [in data = 0]\n",
      "  0) if i know what you are is using this meme be on facebook (p=0.000000) [in data = 0]\n",
      "  1) if i know what you are is using this meme be on the internet (p=0.000000) [in data = 0]\n",
      "  0) what if this christmas is made to do that (p=0.000000) [in data = 0]\n",
      "  1) what if this christmas is made to do that . . . (p=0.000000) [in data = 0]\n",
      "  0) the moment when you have a massive penis and you have to take the order (p=0.000000) [in data = 0]\n",
      "  1) the moment when you have a massive penis and you have to do on the moon (p=0.000000) [in data = 0]\n",
      "  0) if god is just a color . . . . . . . . , why the fuck (p=0.000000) [in data = 0]\n",
      "  1) if god is just a color . . . . . . . . , why the fuck (p=0.000000) [in data = 0]\n",
      "  0) you mean the internet ? (p=0.000000) [in data = 0]\n",
      "  1) you mean the internet is a joke ? (p=0.000000) [in data = 0]\n",
      "  0) wait . . . . i'm not even a tattoo . (p=0.000000) [in data = 0]\n",
      "  1) wait . . . . i'm not even a tattoo . . . . . (p=0.000000) [in data = 0]\n",
      "  0) what if i told you you don't have a picture of me (p=0.000000) [in data = 0]\n",
      "  1) what if i told you you don't have a picture of me in the mirror (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "Captions for image y-u-no.jpg:\n",
      "  0) y u no find me (p=0.000052) [in data = 1]\n",
      "  1) y u no find me ? (p=0.000024) [in data = 0]\n",
      "  0) y u no use windows 7 ? (p=0.000002) [in data = 0]\n",
      "  1) y u no use windows 8 (p=0.000001) [in data = 0]\n",
      "  0) y u no like my cat (p=0.000004) [in data = 0]\n",
      "  1) y u no like my cat ? (p=0.000002) [in data = 0]\n",
      "  0) y u no give me (p=0.000056) [in data = 1]\n",
      "  1) y u no make a meme ! (p=0.000004) [in data = 0]\n",
      "  0) y u no come to trance (p=0.000001) [in data = 0]\n",
      "  1) y u no come to me on time ? (p=0.000000) [in data = 0]\n",
      "  0) y u no take a dump (p=0.000009) [in data = 0]\n",
      "  1) y u no take a dump ? (p=0.000007) [in data = 0]\n",
      "  0) y u no stop looking (p=0.000013) [in data = 0]\n",
      "  1) y u no stop looking at u (p=0.000001) [in data = 0]\n",
      "  0) y u no look at me ? (p=0.000039) [in data = 0]\n",
      "  1) y u no look at me like that ? (p=0.000000) [in data = 0]\n",
      "  0) y u no give a fuck (p=0.000015) [in data = 0]\n",
      "  1) y u no give me a break (p=0.000002) [in data = 1]\n",
      "  0) y u no have a nose ? (p=0.000002) [in data = 0]\n",
      "  1) y u no have a nose ? ! (p=0.000000) [in data = 0]\n",
      "number of captions in data = 3\n",
      "Captions for image stoner-stanley.jpg:\n",
      "  0) it's not the water (p=0.000000) [in data = 0]\n",
      "  1) it's not the first time in your closet , dude (p=0.000000) [in data = 0]\n",
      "  0) how do you smoke weed all day ? (p=0.000000) [in data = 0]\n",
      "  1) how do you smoke weed all day ? yes , i would give you a shot (p=0.000000) [in data = 0]\n",
      "  0) can i have a knife ? (p=0.000000) [in data = 0]\n",
      "  1) can i have a venti latte ? (p=0.000000) [in data = 0]\n",
      "  0) my face when i finish my face (p=0.000000) [in data = 0]\n",
      "  1) my face when i use my teeth at the door (p=0.000000) [in data = 0]\n",
      "  0) fuck you (p=0.000204) [in data = 1]\n",
      "  1) fuck you ! (p=0.000036) [in data = 1]\n",
      "  0) i don't always throw temper tantrums but when i do its all the bad (p=0.000000) [in data = 0]\n",
      "  1) i don't always throw temper tantrums but when i do its all the bad day (p=0.000000) [in data = 0]\n",
      "  0) i'm sorry i can't tell you about it (p=0.000000) [in data = 0]\n",
      "  1) i'm sorry i can't tell you about it too . (p=0.000000) [in data = 0]\n",
      "  0) what do you mean i don't use (p=0.000000) [in data = 0]\n",
      "  1) what do you mean i don't want to look like a slut ? (p=0.000000) [in data = 0]\n",
      "  0) i really wanna have a long time but you can't talk (p=0.000000) [in data = 0]\n",
      "  1) i really wanna have a long time but you can't talk to anything else (p=0.000000) [in data = 0]\n",
      "  0) dude ! ! this is my face ! (p=0.000000) [in data = 0]\n",
      "  1) dude ! ! this is my face when i'm in . . (p=0.000000) [in data = 0]\n",
      "number of captions in data = 2\n",
      "Captions for image stoner-dog.jpg:\n",
      "  0) i'm not afraid i really am a little girl (p=0.000000) [in data = 0]\n",
      "  1) i'm not afraid i really want to drive a prius (p=0.000000) [in data = 0]\n",
      "  0) i'm going to run out of you (p=0.000000) [in data = 0]\n",
      "  1) i'm going to run out of your room . . . fuck off (p=0.000000) [in data = 0]\n",
      "  0) go on a date (p=0.000000) [in data = 1]\n",
      "  1) take a seat with a boner (p=0.000000) [in data = 0]\n",
      "  0) a dog walks into a bar and asks his dog to get high (p=0.000000) [in data = 0]\n",
      "  1) a dog walks into a bar and asks his dog to get a cat (p=0.000000) [in data = 0]\n",
      "  0) how many bears does it take to screw (p=0.000000) [in data = 0]\n",
      "  1) how many bears does (p=0.000000) [in data = 0]\n",
      "  0) this is what you want for the black christmas (p=0.000000) [in data = 0]\n",
      "  1) this is what you want for an hour your lunch . (p=0.000000) [in data = 0]\n",
      "  0) you did what ? ! (p=0.000000) [in data = 0]\n",
      "  1) you did what ? ! ? not today . . . (p=0.000000) [in data = 0]\n",
      "  0) goes to the grocery store gets chased by a bmw (p=0.000000) [in data = 0]\n",
      "  1) goes to the grocery store gets chased by a goat (p=0.000000) [in data = 0]\n",
      "  0) i peed in my pants (p=0.000004) [in data = 0]\n",
      "  1) i peed in the shower and threw it over (p=0.000000) [in data = 0]\n",
      "  0) no food for you (p=0.000001) [in data = 0]\n",
      "  1) no food for you i'm hungry (p=0.000000) [in data = 0]\n",
      "number of captions in data = 1\n",
      "Captions for image advice-dog.jpg:\n",
      "  0) i don't always lick my balls but when i do , it's because i go to sleep (p=0.000000) [in data = 0]\n",
      "  1) i don't always lick my balls but when i do , it's because i go to class (p=0.000000) [in data = 0]\n",
      "  0) take the shit out (p=0.000000) [in data = 0]\n",
      "  1) take the shit out of space (p=0.000000) [in data = 0]\n",
      "  0) what does the fox say (p=0.000004) [in data = 1]\n",
      "  1) what does the fox say when he is the same as me ? that's a racist . (p=0.000000) [in data = 0]\n",
      "  0) when i have an idea gets out of my book (p=0.000000) [in data = 0]\n",
      "  1) when i have an idea gets out of my litterbox this is a fact (p=0.000000) [in data = 0]\n",
      "  0) find a perfect house for a human day (p=0.000000) [in data = 0]\n",
      "  1) find a perfect house for a pool can't find it (p=0.000000) [in data = 0]\n",
      "  0) take a break out of the toilet get a boner (p=0.000000) [in data = 0]\n",
      "  1) take a break out of the toilet get a boner out (p=0.000000) [in data = 0]\n",
      "  0) read foul bachelor frog didn't respond to all the people (p=0.000000) [in data = 0]\n",
      "  1) read foul bachelor frog didn't respond to all the messages (p=0.000000) [in data = 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) happy birthday from the world (p=0.000000) [in data = 0]\n",
      "  1) happy birthday from the world . (p=0.000000) [in data = 0]\n",
      "  0) why dont you just look at me ? no , i do not (p=0.000000) [in data = 0]\n",
      "  1) why dont you just look at me ? no , i know how to make some memes (p=0.000000) [in data = 0]\n",
      "  0) what do you think i'm a virgin (p=0.000000) [in data = 0]\n",
      "  1) what do you think you're a vegan (p=0.000000) [in data = 0]\n",
      "number of captions in data = 1\n",
      "(total number of captions in data = 15) percent in data = 0.068807\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "filenames = [os.path.join(image_dir, f) for f in os.listdir(input_files) if f.endswith('.jpg')]\n",
    "print(filenames)\n",
    "tf.logging.info(\"Running caption generation on %d files matching %s\",len(filenames), input_files)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    \n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "    generator = caption_generator.CaptionGenerator(model, vocab, beam_size=config.beam_size)\n",
    "    num_in_data_total = 0\n",
    "    num_captions = 0\n",
    "    for i,filename in enumerate(filenames):\n",
    "      with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "        #image = f.read()\n",
    "        image = Image.open(f)\n",
    "        image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0\n",
    "        \n",
    "      print(\"Captions for image %s:\" % os.path.basename(filenames[i]))\n",
    "      num_in_data = 0\n",
    "      for k in range(10):\n",
    "          captions = generator.beam_search(sess, image)\n",
    "            \n",
    "          for i, caption in enumerate(captions):\n",
    "            # Ignore begin and end words.\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            in_data = 0\n",
    "            if b_any(sentence in capt for capt in data_captions):\n",
    "                in_data = 1\n",
    "                num_in_data += 1\n",
    "                num_in_data_total += 1\n",
    "                num_captions += 1\n",
    "            else:\n",
    "                num_captions += 1\n",
    "            print(\"  %d) %s (p=%f) [in data = %d]\" % (i, sentence, math.exp(caption.logprob),in_data))\n",
    "      print(\"number of captions in data = %d\" % (num_in_data))\n",
    "    print(\"(total number of captions in data = %d) percent in data = %f\" % (num_in_data_total,(num_in_data_total/num_captions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Restoring parameters from trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-1000000\n",
      "(1024,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "seq_embeddings = np.ones([1, 2, 300])\n",
    "state_feed = np.ones([1, 2, 1024])\n",
    "image_feed = np.ones([299,299,3])\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    initial_state_output = sess.run(\n",
    "        #fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        fetches=[\"lstm/initial_state:0\"],\n",
    "        feed_dict={\"image_feed:0\": image_feed\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            #\"lstm/state_feed:0\": state_feed,\n",
    "            #\"seq_embeddings:0\": seq_embeddings,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    print(initial_state_output[0][0].shape)\n",
    "    #print(softmax_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.0628893e-01 -2.1196607e-10 -1.0000000e+00 -6.6239569e-24\n",
      " -9.9990189e-01 -1.0000000e+00  9.9999964e-01 -1.0000000e+00\n",
      " -1.3523345e-14  1.2684521e-29]\n"
     ]
    }
   ],
   "source": [
    "print(initial_state_output[0][0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('stateoutputTEST.txt',state_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_CHECKPOINT_FILE = \"trainlogSGD/model.ckpt-600000\"\n",
    "NEW_CHECKPOINT_FILE = \"trainlogSGDNEW/model.ckpt-600000\"\n",
    "\n",
    "import tensorflow as tf\n",
    "vars_to_rename = {\n",
    "    \"lstm/basic_lstm_cell/weights\": \"lstm/basic_lstm_cell/kernel\",\n",
    "    \"lstm/basic_lstm_cell/biases\": \"lstm/basic_lstm_cell/bias\",\n",
    "}\n",
    "new_checkpoint_vars = {}\n",
    "reader = tf.train.NewCheckpointReader(OLD_CHECKPOINT_FILE)\n",
    "for old_name in reader.get_variable_to_shape_map():\n",
    "  if old_name in vars_to_rename:\n",
    "    new_name = vars_to_rename[old_name]\n",
    "  else:\n",
    "    new_name = old_name\n",
    "  new_checkpoint_vars[new_name] = tf.Variable(reader.get_tensor(old_name))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(new_checkpoint_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  saver.save(sess, NEW_CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
