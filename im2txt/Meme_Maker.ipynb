{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, 'im2txt/inference_utils')\n",
    "sys.path.insert(0, 'im2txt/ops')\n",
    "import caption_generator\n",
    "import image_processing\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "image_dir = os.path.join(current_dir, 'Jmemes')\n",
    "\n",
    "\n",
    "checkpoint_path=\"trainlogIncNEW\"\n",
    "vocab_file =\"vocab4.txt\"\n",
    "input_files =\"Jmemes\"         \n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "It's splitting\n",
      "gate_inputs0 Tensor(\"lstm/basic_lstm_cell/MatMul_1:0\", shape=(1, 1, 2048), dtype=float32)\n",
      "gate_inputs1 Tensor(\"lstm/basic_lstm_cell/MatMul_2:0\", shape=(1, 1, 2048), dtype=float32)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "gate_inputs Tensor(\"lstm/basic_lstm_cell/concat_2:0\", shape=(1, 2, 2048), dtype=float32)\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/ SPLITTING\n"
     ]
    }
   ],
   "source": [
    "#configuration\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(config,\n",
    "                                               checkpoint_path)\n",
    "g.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.Vocabulary(vocab_file)\n",
    "\n",
    "with open('Captions.txt','r') as f:\n",
    "    data_captions = f.readlines()\n",
    "data_captions = [s.lower() for s in data_captions]\n",
    "  \n",
    "with open('ordered_memes.txt','r') as f:\n",
    "    ordered_memes = f.readlines()\n",
    "ordered_memes = [meme.replace('\\n','') for meme in ordered_memes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/sassy-gay-snape.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/romneyhood.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/ridiculously-photogenic-metalhead-guy.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/sad-dog.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/sudden-realization-ralph.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/stoner-stanley.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/stoner-dog.jpg', '/Users/freedmand/scraps/danklearning2/im2txt/Jmemes/advice-dog.jpg']\n",
      "INFO:tensorflow:Running caption generation on 8 files matching Jmemes\n",
      "INFO:tensorflow:Loading model from checkpoint: trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "Captions for image sassy-gay-snape.jpg:\n",
      "  0) i'm not a hipster im just like (p=0.000000) [in data = 0]\n",
      "  1) i'm not a hipster im just like asian (p=0.000000) [in data = 0]\n",
      "  0) what if lavos overslept (p=0.000006) [in data = 1]\n",
      "  1) what if lavos overslept in a game ? (p=0.000000) [in data = 0]\n",
      "  0) i like metal (p=0.000006) [in data = 1]\n",
      "  1) i play minecraft . . (p=0.000000) [in data = 0]\n",
      "  0) i am an angel but i love me (p=0.000000) [in data = 0]\n",
      "  1) i am an angel but i need to leave a room (p=0.000000) [in data = 0]\n",
      "  0) your name is randy ? i'm so sorry . . (p=0.000000) [in data = 0]\n",
      "  1) your name is randy ? i'm so sorry . . . . (p=0.000000) [in data = 0]\n",
      "  0) you're not your father ? ? (p=0.000000) [in data = 0]\n",
      "  1) you're not your father ? ? only a sith (p=0.000000) [in data = 0]\n",
      "  0) i want a girl i can have sex (p=0.000000) [in data = 0]\n",
      "  1) i want a girl i can have sex in your dreams (p=0.000000) [in data = 0]\n",
      "  0) this is what happens when you have a crush on her . (p=0.000000) [in data = 0]\n",
      "  1) this is what happens when you have a crush on her for you (p=0.000000) [in data = 0]\n",
      "  0) i want you for a hug and a day (p=0.000000) [in data = 0]\n",
      "  1) i want you for a hug and a day . (p=0.000000) [in data = 0]\n",
      "  0) i have a feeling for you . (p=0.000000) [in data = 0]\n",
      "  1) i have a feeling for you . get that bitch . (p=0.000000) [in data = 0]\n",
      "number of captions in data = 2\n",
      "Captions for image romneyhood.jpg:\n",
      "  0) if you can't afford a way to kill you , you know it . (p=0.000000) [in data = 0]\n",
      "  0) if i change my facebook status i don't give a fuck (p=0.000000) [in data = 0]\n",
      "  1) if i change my facebook status i don't give a shit (p=0.000000) [in data = 0]\n",
      "  0) i love u (p=0.000008) [in data = 1]\n",
      "  1) i dont always drive a jet but when i do , i use it in the air (p=0.000000) [in data = 0]\n",
      "  0) what ? i don't get the fuck up (p=0.000000) [in data = 0]\n",
      "  1) what ? i don't get the fuck out (p=0.000000) [in data = 0]\n",
      "  0) what the hell is this ? (p=0.000001) [in data = 0]\n",
      "  1) what the hell is this shit ! ? (p=0.000000) [in data = 0]\n",
      "  0) says he needs a girlfriend (p=0.000000) [in data = 0]\n",
      "  1) says he needs to cut the grass wears his shirt (p=0.000000) [in data = 0]\n",
      "  0) what's the only thing you want in life to get ? i don't get it (p=0.000000) [in data = 0]\n",
      "  1) what's the only thing you want in life to get ? i don't get it ! (p=0.000000) [in data = 0]\n",
      "  0) i don't always call the police but when i do its in the 4th quarter (p=0.000000) [in data = 0]\n",
      "  1) i don't always call the police but when i do its in the 4th quarter time (p=0.000000) [in data = 0]\n",
      "  0) this is me how can i find you . (p=0.000000) [in data = 0]\n",
      "  1) this is me how can i find you . . . . in america ! (p=0.000000) [in data = 0]\n",
      "  0) this (p=0.000048) [in data = 1]\n",
      "  1) this is the worst game ever (p=0.000001) [in data = 1]\n",
      "number of captions in data = 3\n",
      "Captions for image ridiculously-photogenic-metalhead-guy.jpg:\n",
      "  0) goes to gym for not (p=0.000000) [in data = 0]\n",
      "  1) goes to gym for 12 year olds still going to see you at bars (p=0.000000) [in data = 0]\n",
      "  0) goes to school tomorrow is a bunch of years (p=0.000000) [in data = 0]\n",
      "  1) goes to school tomorrow is a bunch (p=0.000000) [in data = 0]\n",
      "  0) wants to become a ginger becomes a rockstar (p=0.000000) [in data = 0]\n",
      "  1) wants to become a ginger becomes gay (p=0.000000) [in data = 0]\n",
      "  0) goes to class gets sick for you (p=0.000000) [in data = 0]\n",
      "  1) goes to class gets sick for an hour wakes (p=0.000000) [in data = 0]\n",
      "  0) plays with a metalhead still misses him (p=0.000000) [in data = 0]\n",
      "  1) plays with a metalhead still wants (p=0.000000) [in data = 0]\n",
      "  0) goes to the bathroom at 9 00 (p=0.000000) [in data = 0]\n",
      "  1) goes to the bathroom at a party (p=0.000000) [in data = 0]\n",
      "  0) when you finally finished drinking the hunger games (p=0.000000) [in data = 0]\n",
      "  1) when you come out while listening to the dance floor (p=0.000000) [in data = 0]\n",
      "  0) goes to a metallica concert concert . . . . (p=0.000000) [in data = 0]\n",
      "  1) goes to a metallica concert concert . . . . . . not impressed . (p=0.000000) [in data = 0]\n",
      "  0) goes to hell gets boner (p=0.000001) [in data = 0]\n",
      "  1) goes to hell gets shot (p=0.000000) [in data = 0]\n",
      "  0) what do you mean i have a job (p=0.000000) [in data = 0]\n",
      "  1) what do you mean i have a job interview ? (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "Captions for image sad-dog.jpg:\n",
      "  0) why are you so serious ? (p=0.000001) [in data = 0]\n",
      "  1) why are you so serious ? ! ? (p=0.000000) [in data = 0]\n",
      "  0) i'm the doctor with a man (p=0.000000) [in data = 0]\n",
      "  1) i'm the doctor with a brother . i am a father . (p=0.000000) [in data = 0]\n",
      "  0) oh so (p=0.000007) [in data = 1]\n",
      "  1) the only thing you say is a great idea , what (p=0.000000) [in data = 0]\n",
      "  0) i don't always be a meme but when i do , i use the wrong (p=0.000000) [in data = 0]\n",
      "  1) i don't always be a meme but when i do , i use the word (p=0.000000) [in data = 0]\n",
      "  0) if you listen to the dark knight rises , you'll be fine (p=0.000000) [in data = 0]\n",
      "  1) if you listen to the dark knight rises , you'll be fine ! (p=0.000000) [in data = 0]\n",
      "  0) happy birthday ! (p=0.000097) [in data = 1]\n",
      "  1) happy birthday anna ! (p=0.000013) [in data = 0]\n",
      "  0) what are you looking at ? (p=0.000007) [in data = 0]\n",
      "  1) what are you looking for ? (p=0.000005) [in data = 0]\n",
      "  0) i am not a dog (p=0.000003) [in data = 0]\n",
      "  1) i am not a dog ! ! (p=0.000000) [in data = 0]\n",
      "  0) my favorite movie is the worst part (p=0.000000) [in data = 0]\n",
      "  1) my favorite movie is the worst part of life (p=0.000000) [in data = 0]\n",
      "  0) i'm so ugly (p=0.000006) [in data = 1]\n",
      "  1) i'm so excited for a week (p=0.000000) [in data = 0]\n",
      "number of captions in data = 3\n",
      "Captions for image sudden-realization-ralph.jpg:\n",
      "  0) if you don't like this meme then you might be a man (p=0.000000) [in data = 0]\n",
      "  1) if you don't like this meme then you might be a man ! (p=0.000000) [in data = 0]\n",
      "  0) the pope is not gay (p=0.000000) [in data = 0]\n",
      "  1) the pope is not a real muslim (p=0.000000) [in data = 0]\n",
      "  0) an apple . . . just happened to the internet (p=0.000000) [in data = 0]\n",
      "  1) an apple . . . just made a funny meme (p=0.000000) [in data = 0]\n",
      "  0) goes to school to become a meme becomes a meme (p=0.000000) [in data = 0]\n",
      "  1) goes to school to become a meme becomes a philosopher (p=0.000000) [in data = 0]\n",
      "  0) and then why does everyone do that ? (p=0.000000) [in data = 0]\n",
      "  1) and then why does he give a fuck (p=0.000000) [in data = 0]\n",
      "  0) his name is justin bieber (p=0.000002) [in data = 0]\n",
      "  1) his name is paul (p=0.000001) [in data = 1]\n",
      "  0) the only reason god is created by which one is the best part of the world . (p=0.000000) [in data = 0]\n",
      "  0) the face you talk to me and you will see me ? (p=0.000000) [in data = 0]\n",
      "  0) the word of the day is for the day of the night (p=0.000000) [in data = 0]\n",
      "  1) the word of the day is just a lot of anger (p=0.000000) [in data = 0]\n",
      "  0) what the fuck is a hufflepuff ? (p=0.000008) [in data = 0]\n",
      "  1) what the fuck is a hufflepuff doing right in this class (p=0.000000) [in data = 0]\n",
      "number of captions in data = 1\n",
      "Captions for image stoner-stanley.jpg:\n",
      "  0) i used to be fat then i took an arrow to the knee (p=0.000000) [in data = 0]\n",
      "  1) i used to be fat then i took an arrow in the knee (p=0.000000) [in data = 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0) look at me im a ginger (p=0.000001) [in data = 0]\n",
      "  1) look at me im a ginger cunt (p=0.000000) [in data = 0]\n",
      "  0) what ? (p=0.000119) [in data = 1]\n",
      "  1) what ? is that the car ? (p=0.000000) [in data = 0]\n",
      "  0) dude , i think you can see me (p=0.000000) [in data = 0]\n",
      "  1) dude , i think you can see the world (p=0.000000) [in data = 0]\n",
      "  0) dude ! i lost my tooth ! (p=0.000000) [in data = 0]\n",
      "  1) dude ! i lost my tooth ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) dude i'm an apple (p=0.000000) [in data = 0]\n",
      "  1) dude i'm an avid gamer i am just like (p=0.000000) [in data = 0]\n",
      "  0) dude , i think i have to let the dogs die . . . (p=0.000000) [in data = 0]\n",
      "  1) dude , i think i have to let the dogs die . . . stop sending them . (p=0.000000) [in data = 0]\n",
      "  0) i was like (p=0.000006) [in data = 1]\n",
      "  1) i was like yolo (p=0.000001) [in data = 1]\n",
      "  0) what does that mean cheese (p=0.000000) [in data = 0]\n",
      "  1) what does that mean say you can't handle the truth ? (p=0.000000) [in data = 0]\n",
      "  0) i cant eat (p=0.000000) [in data = 1]\n",
      "  1) i cant wait to see you from a picture of the new town (p=0.000000) [in data = 0]\n",
      "number of captions in data = 4\n",
      "Captions for image stoner-dog.jpg:\n",
      "  0) this is sparta (p=0.000025) [in data = 1]\n",
      "  1) this guy (p=0.000014) [in data = 1]\n",
      "  0) this is what i do when the teacher says . (p=0.000000) [in data = 0]\n",
      "  1) this is what i do when my mom is in jail (p=0.000000) [in data = 0]\n",
      "  0) i dont know what it was about it (p=0.000000) [in data = 0]\n",
      "  1) i dont know what it was about it ! (p=0.000000) [in data = 0]\n",
      "  0) the only reason we have a bunch of my life (p=0.000000) [in data = 0]\n",
      "  1) the only reason we have a bunch of of their kids (p=0.000000) [in data = 0]\n",
      "  0) i'm so high i'm a dog (p=0.000000) [in data = 0]\n",
      "  1) i'm so high i'm a dog ! (p=0.000000) [in data = 0]\n",
      "  0) dude i'm a towel (p=0.000000) [in data = 0]\n",
      "  1) dude im a camel (p=0.000000) [in data = 0]\n",
      "  0) i have you (p=0.000002) [in data = 1]\n",
      "  1) i got a gun ! (p=0.000000) [in data = 0]\n",
      "  0) woof woof woof (p=0.000657) [in data = 1]\n",
      "  1) woof woof woof woof woof (p=0.000261) [in data = 0]\n",
      "  0) dude , i was gonna go to the party . (p=0.000000) [in data = 0]\n",
      "  1) dude , i was gonna go to the party . . today (p=0.000000) [in data = 0]\n",
      "  0) oh yeah i pooped (p=0.000000) [in data = 0]\n",
      "  1) oh yeah i pooped on the floor (p=0.000000) [in data = 0]\n",
      "number of captions in data = 4\n",
      "Captions for image advice-dog.jpg:\n",
      "  0) you want a hug ? i'll give you a hug (p=0.000000) [in data = 0]\n",
      "  1) you want a hug ? i'll give you a ride (p=0.000000) [in data = 0]\n",
      "  0) you want to eat a chicken ? i can't think of anything ! ! (p=0.000000) [in data = 0]\n",
      "  1) you want to eat a chicken ? i can't think of anything ! ! ! (p=0.000000) [in data = 0]\n",
      "  0) go ahead to get fed up at night gives you the money (p=0.000000) [in data = 0]\n",
      "  1) go ahead to get fed up at night gives you the next nap (p=0.000000) [in data = 0]\n",
      "  0) go to school ? eat it . (p=0.000000) [in data = 0]\n",
      "  1) go to school ? eat all your brains (p=0.000000) [in data = 0]\n",
      "  0) get a job interview give you your job (p=0.000000) [in data = 0]\n",
      "  1) get a job interview give you free to leave (p=0.000000) [in data = 0]\n",
      "  0) do the laundry with a toilet (p=0.000000) [in data = 0]\n",
      "  1) do the laundry with a cow with your pants on the toilet ? ? (p=0.000000) [in data = 0]\n",
      "  0) get a shower , go to sleep (p=0.000000) [in data = 0]\n",
      "  1) get a shower , go to bed , take a shit (p=0.000000) [in data = 0]\n",
      "  0) oh yeah ! ! ! no ! ! ! (p=0.000000) [in data = 0]\n",
      "  1) oh yeah ! ! ! no ! ! ! it's friday ! ! (p=0.000000) [in data = 0]\n",
      "  0) i got this money (p=0.000000) [in data = 0]\n",
      "  1) i got that haircut before you come (p=0.000000) [in data = 0]\n",
      "  0) hey , look at you all the fucks i give (p=0.000000) [in data = 0]\n",
      "  1) hey , look at you all the fucks i give from mom (p=0.000000) [in data = 0]\n",
      "number of captions in data = 0\n",
      "(total number of captions in data = 17) percent in data = 0.108280\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "filenames = [os.path.join(image_dir, f) for f in os.listdir(input_files) if f.endswith('.jpg')]\n",
    "print(filenames)\n",
    "tf.logging.info(\"Running caption generation on %d files matching %s\",len(filenames), input_files)\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    \n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "    generator = caption_generator.CaptionGenerator(model, vocab, beam_size=config.beam_size)\n",
    "    num_in_data_total = 0\n",
    "    num_captions = 0\n",
    "    for i,filename in enumerate(filenames):\n",
    "      with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "        #image = f.read()\n",
    "        image = Image.open(f)\n",
    "        image = ((np.array(image.resize((299,299)))/255.0)-0.5)*2.0 \n",
    "        \n",
    "      print(\"Captions for image %s:\" % os.path.basename(filenames[i]))\n",
    "      num_in_data = 0\n",
    "      for k in range(10):\n",
    "          captions = generator.beam_search(sess, image)\n",
    "            \n",
    "          for i, caption in enumerate(captions):\n",
    "            # Ignore begin and end words.\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            in_data = 0\n",
    "            if b_any(sentence in capt for capt in data_captions):\n",
    "                in_data = 1\n",
    "                num_in_data += 1\n",
    "                num_in_data_total += 1\n",
    "                num_captions += 1\n",
    "            else:\n",
    "                num_captions += 1\n",
    "            print(\"  %d) %s (p=%f) [in data = %d]\" % (i, sentence, math.exp(caption.logprob),in_data))\n",
    "      print(\"number of captions in data = %d\" % (num_in_data))\n",
    "    print(\"(total number of captions in data = %d) percent in data = %f\" % (num_in_data_total,(num_in_data_total/num_captions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "x = np.array([[np.ones([300])*0.5,np.ones([300])*0.5]])\n",
    "print(x[0,0,15])\n",
    "print(x[0,1,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "[0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6]\n",
      "[0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6]\n",
      "INFO:tensorflow:Loading model from checkpoint: trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from trainlogIncNEW/model.ckpt\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt\n",
      "(1, 2, 1024)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "seq_embeddings = np.array([[np.ones([300])*0.5,np.ones([300])*0.5]])\n",
    "state_feed = np.array([[np.ones([1024])*0.6,np.ones([1024])*0.6]])\n",
    "print(seq_embeddings[0,0,:10])\n",
    "print(seq_embeddings[0,1,:10])\n",
    "print(state_feed[0,0,:10])\n",
    "print(state_feed[0,1,:10])\n",
    "image_feed = np.ones([299,299,3])*-0.2156862745\n",
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    softmax, state = sess.run(\n",
    "        fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "        #fetches=[\"lstm/initial_state:0\"],\n",
    "        feed_dict={#\"image_feed:0\": image_feed\n",
    "            #\"input_feed:0\": input_feed,\n",
    "            \"lstm/state_feed:0\": state_feed,\n",
    "            \"seq_embeddings:0\": seq_embeddings,\n",
    "            #\"seq_embedding/embedding_map:0\": self.embedding_map\n",
    "        })\n",
    "    print(state.shape)\n",
    "    #print(softmax_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43284872  0.62102246  0.11169446  0.7932278  -0.04157066 -0.4009313\n",
      "  0.59577763  0.06588744 -0.30913225 -0.40599316]\n",
      "[-0.43284872  0.62102246  0.11169446  0.7932278  -0.04157066 -0.4009313\n",
      "  0.59577763  0.06588744 -0.30913225 -0.40599316]\n"
     ]
    }
   ],
   "source": [
    "print(state[0,1,90:100])\n",
    "print(state[0,0,90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_state_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-fec188ae6287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initial_state_output' is not defined"
     ]
    }
   ],
   "source": [
    "print(initial_state_output[0][0][0])\n",
    "print(initial_state_output[0][0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('stateoutputTEST.txt',state_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD_CHECKPOINT_FILE = \"trainlogSGD/model.ckpt-600000\"\n",
    "NEW_CHECKPOINT_FILE = \"trainlogSGDNEW/model.ckpt-600000\"\n",
    "\n",
    "import tensorflow as tf\n",
    "vars_to_rename = {\n",
    "    \"lstm/basic_lstm_cell/weights\": \"lstm/basic_lstm_cell/kernel\",\n",
    "    \"lstm/basic_lstm_cell/biases\": \"lstm/basic_lstm_cell/bias\",\n",
    "}\n",
    "new_checkpoint_vars = {}\n",
    "reader = tf.train.NewCheckpointReader(OLD_CHECKPOINT_FILE)\n",
    "for old_name in reader.get_variable_to_shape_map():\n",
    "  if old_name in vars_to_rename:\n",
    "    new_name = vars_to_rename[old_name]\n",
    "  else:\n",
    "    new_name = old_name\n",
    "  new_checkpoint_vars[new_name] = tf.Variable(reader.get_tensor(old_name))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(new_checkpoint_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  saver.save(sess, NEW_CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
