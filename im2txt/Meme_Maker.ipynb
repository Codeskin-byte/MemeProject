{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ALP/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __builtin__ import any as b_any\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from alexnet import AlexNet\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import configuration\n",
    "import inference_wrapper\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/ALP/PycharmProjects/MemeProject/im2txt/inference_utils')\n",
    "import caption_generator\n",
    "import vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "image_dir = os.path.join(current_dir, 'Jmemes')\n",
    "\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "\n",
    "tf.flags.DEFINE_string(\"checkpoint_path\", \"trainlogIncNEW\",\n",
    "                       \"Model checkpoint file or directory containing a \"\n",
    "                       \"model checkpoint file.\")\n",
    "tf.flags.DEFINE_string(\"vocab_file\", \"vocab4.txt\", \"Text file containing the vocabulary.\")\n",
    "tf.flags.DEFINE_string(\"input_files\", \"Jmemes\",\n",
    "                       \"File pattern or comma-separated list of file patterns \"\n",
    "                       \"of image files.\")\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n"
     ]
    }
   ],
   "source": [
    "#configuration\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(config,\n",
    "                                               FLAGS.checkpoint_path)\n",
    "g.finalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    #print(tf.trainable_variables())\n",
    "    var = [v for v in tf.trainable_variables() if v.name == \"seq_embedding/map:0\"][0]\n",
    "    embeddings = sess.run(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "em_orig = np.loadtxt('embedding_matrix5')\n",
    "for i,ting in enumerate(embeddings):\n",
    "    if em_orig[i] != embeddings[i]:\n",
    "        print('YESSS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: vocab4.txt\n",
      "INFO:tensorflow:Created vocabulary with 38521 words\n",
      "['/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/NOSE.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/one-does-not-simply.jpg', '/Users/ALP/PycharmProjects/MemeProject/im2txt/Jmemes/y-u-no.jpg']\n",
      "INFO:tensorflow:Running caption generation on 3 files matching Jmemes\n"
     ]
    }
   ],
   "source": [
    "vocab = vocabulary.Vocabulary(FLAGS.vocab_file)\n",
    "\n",
    "with open('Captions.txt','r') as f:\n",
    "    data_captions = f.readlines()\n",
    "data_captions = [s.lower() for s in data_captions]\n",
    "  \n",
    "with open('ordered_memes.txt','r') as f:\n",
    "    ordered_memes = f.readlines()\n",
    "ordered_memes = [meme.replace('\\n','') for meme in ordered_memes]\n",
    "#convert jpg image(s) into iamge representations using alexnet:\n",
    "filenames = [os.path.join(image_dir, f) for f in os.listdir(FLAGS.input_files) if f.endswith('.jpg')]\n",
    "#filenames = [os.path.join(image_dir, f) for f in ordered_memes[150:160] + ['TutorPP.jpg']]\n",
    "print(filenames)\n",
    "tf.logging.info(\"Running caption generation on %d files matching %s\",len(filenames), FLAGS.input_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Restoring parameters from trainlogIncNEW/model.ckpt-1000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-1000000\n",
      "Captions for image NOSE.jpg:\n",
      "  0) i don't always go to school but when i do , i do it (p=0.000000) [in data = 0]\n",
      "  1) i don't always go to school but when i do , i make sure i'm a lawyer (p=0.000000) [in data = 0]\n",
      "  2) i don't always go to school but when i do , i make sure i'm a dog (p=0.000000) [in data = 0]\n",
      "  0) happy birthday girl (p=0.000041) [in data = 1]\n",
      "  1) happy birthday girl ! (p=0.000013) [in data = 0]\n",
      "  2) happy birthday girl ! ! (p=0.000003) [in data = 0]\n",
      "  0) i am not gay (p=0.000005) [in data = 1]\n",
      "  1) i am a pussy destroyer (p=0.000001) [in data = 0]\n",
      "  2) i am not a virgin (p=0.000001) [in data = 0]\n",
      "  0) i have a good feeling about today (p=0.000000) [in data = 1]\n",
      "  1) i have a good feeling about my family (p=0.000000) [in data = 0]\n",
      "  2) i have a good feeling about today you are the best (p=0.000000) [in data = 0]\n",
      "  0) hey i just met you (p=0.000044) [in data = 1]\n",
      "  1) hey i just met you and this is crazy (p=0.000015) [in data = 1]\n",
      "  2) i hate you (p=0.000058) [in data = 1]\n",
      "  0) i have a dream . (p=0.000000) [in data = 0]\n",
      "  1) i have a dream . . . . . (p=0.000000) [in data = 0]\n",
      "  2) i have a dream . . . . . . . . i'm a virgin (p=0.000000) [in data = 0]\n",
      "  0) hey baby ! ! (p=0.000002) [in data = 0]\n",
      "  1) hey baby , i heard you like . . . ? (p=0.000000) [in data = 0]\n",
      "  2) hey baby , i heard you like . . so i got your car (p=0.000000) [in data = 0]\n",
      "  0) i have no idea what i'm doing (p=0.000015) [in data = 1]\n",
      "  1) hey , i just met you , and this is crazy but heres my dungeon , so come (p=0.000000) [in data = 0]\n",
      "  0) i know what you mean (p=0.000001) [in data = 1]\n",
      "  1) i just got a new iphone (p=0.000000) [in data = 0]\n",
      "  2) i just got a new haircut ! (p=0.000000) [in data = 0]\n",
      "  0) i can count to potato (p=0.000054) [in data = 1]\n",
      "  1) i can count to potato ! (p=0.000005) [in data = 0]\n",
      "  2) i can count to potato ! ! ! (p=0.000001) [in data = 0]\n",
      "number of captions in data = 9\n",
      "Captions for image one-does-not-simply.jpg:\n",
      "  0) one does not simply look at your nose (p=0.000003) [in data = 0]\n",
      "  1) one does not simply become a rapper in the matrix (p=0.000000) [in data = 0]\n",
      "  2) one does not simply look at your eyes open (p=0.000000) [in data = 0]\n",
      "  0) one does not simply go to bed (p=0.000131) [in data = 0]\n",
      "  1) one does not simply go to the beach (p=0.000016) [in data = 0]\n",
      "  2) one does not simply go to the gym without fapping (p=0.000001) [in data = 0]\n",
      "  0) one does not simply take a photo of myself (p=0.000000) [in data = 0]\n",
      "  1) one does not simply take a photo of life (p=0.000000) [in data = 0]\n",
      "  2) one does not simply take out the money (p=0.000000) [in data = 0]\n",
      "  0) one does not simply eat a meme (p=0.000018) [in data = 0]\n",
      "  1) one does not simply find the word (p=0.000003) [in data = 0]\n",
      "  2) one does not simply eat a meme . (p=0.000001) [in data = 0]\n",
      "  0) one does not simply eat a banana (p=0.000047) [in data = 1]\n",
      "  1) one does not simply put a meme on facebook (p=0.000008) [in data = 0]\n",
      "  2) one does not simply put a meme in the background (p=0.000000) [in data = 0]\n",
      "  0) one does not simply eat a sandwich (p=0.000077) [in data = 0]\n",
      "  1) one does not simply eat a banana (p=0.000047) [in data = 1]\n",
      "  2) one does not simply eat a banana without crust (p=0.000001) [in data = 0]\n",
      "  0) one does not simply make a meme (p=0.000441) [in data = 0]\n",
      "  1) one does not simply go to bed (p=0.000131) [in data = 0]\n",
      "  2) one does not simply go to the gym (p=0.000079) [in data = 0]\n",
      "  0) one does not simply play minecraft (p=0.000228) [in data = 0]\n",
      "  1) one does not simply play with a band (p=0.000002) [in data = 0]\n",
      "  2) one does not simply play minecraft for the first time (p=0.000001) [in data = 0]\n",
      "  0) one does not simply eat a sandwich (p=0.000077) [in data = 0]\n",
      "  1) one does not simply eat a cat (p=0.000020) [in data = 0]\n",
      "  2) one does not simply eat a sandwich without making a burrito (p=0.000000) [in data = 0]\n",
      "  0) one does not simply play fifa (p=0.000082) [in data = 0]\n",
      "  1) one does not simply play fifa 13 (p=0.000022) [in data = 0]\n",
      "  2) one does not simply play fifa . . . (p=0.000002) [in data = 0]\n",
      "number of captions in data = 2\n",
      "Captions for image y-u-no.jpg:\n",
      "  0) y u no die (p=0.000350) [in data = 1]\n",
      "  1) y u no die ? (p=0.000220) [in data = 1]\n",
      "  2) y u no stop looking (p=0.000012) [in data = 0]\n",
      "  0) meme generator y u so funny ? (p=0.000044) [in data = 0]\n",
      "  1) meme generator y u so funny (p=0.000041) [in data = 0]\n",
      "  2) meme generator y u no upload gifs ? (p=0.000009) [in data = 0]\n",
      "  0) y u no work (p=0.002098) [in data = 1]\n",
      "  1) facebook y u no work ? (p=0.000467) [in data = 0]\n",
      "  2) y u no answer (p=0.000272) [in data = 1]\n",
      "  0) meme generator y u no stop me ? (p=0.000003) [in data = 0]\n",
      "  1) meme generator y u no stop me (p=0.000002) [in data = 0]\n",
      "  2) meme generator y u no stop bleeding (p=0.000002) [in data = 0]\n",
      "  0) justin bieber y u no look at me ? (p=0.000004) [in data = 0]\n",
      "  1) justin bieber y u no look like me ? (p=0.000003) [in data = 0]\n",
      "  2) justin bieber y u no look like me (p=0.000004) [in data = 0]\n",
      "  0) y u no work ? (p=0.001859) [in data = 1]\n",
      "  1) meme generator y u no answer ? (p=0.000006) [in data = 0]\n",
      "  2) meme generator y u no leave (p=0.000005) [in data = 0]\n",
      "  0) internet explorer y u so slow ? (p=0.000078) [in data = 0]\n",
      "  1) internet explorer y u so slow (p=0.000035) [in data = 0]\n",
      "  2) internet explorer y u so slow ? ! (p=0.000005) [in data = 0]\n",
      "  0) y u no call me (p=0.000130) [in data = 1]\n",
      "  1) y u no call me ? (p=0.000092) [in data = 1]\n",
      "  2) y u no text me ? (p=0.000066) [in data = 0]\n",
      "  0) y u no like me (p=0.000417) [in data = 1]\n",
      "  1) y u no like me ? (p=0.000295) [in data = 1]\n",
      "  2) y u no like me ? ! (p=0.000059) [in data = 0]\n",
      "  0) y u no like me ? (p=0.000295) [in data = 1]\n",
      "  1) y u no like me ? ! (p=0.000059) [in data = 0]\n",
      "  2) y u no like me ! (p=0.000039) [in data = 0]\n",
      "number of captions in data = 10\n",
      "(total number of captions in data = 21) percent in data = 0.235955\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    # Load the model from checkpoint.\n",
    "    restore_fn(sess)\n",
    "    \n",
    "    # Prepare the caption generator. Here we are implicitly using the default\n",
    "    # beam search parameters. See caption_generator.py for a description of the\n",
    "    # available beam search parameters.\n",
    "    generator = caption_generator.CaptionGenerator(model, vocab, beam_size=config.beam_size)\n",
    "    num_in_data_total = 0\n",
    "    num_captions = 0\n",
    "    for i,filename in enumerate(filenames):\n",
    "      with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "        image = f.read()\n",
    "      print(\"Captions for image %s:\" % os.path.basename(filenames[i]))\n",
    "      num_in_data = 0\n",
    "      for k in range(10):\n",
    "          captions = generator.beam_search(sess, image)\n",
    "            \n",
    "          for i, caption in enumerate(captions):\n",
    "            # Ignore begin and end words.\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            in_data = 0\n",
    "            if b_any(sentence in capt for capt in data_captions):\n",
    "                in_data = 1\n",
    "                num_in_data += 1\n",
    "                num_in_data_total += 1\n",
    "                num_captions += 1\n",
    "            else:\n",
    "                num_captions += 1\n",
    "            print(\"  %d) %s (p=%f) [in data = %d]\" % (i, sentence, math.exp(caption.logprob),in_data))\n",
    "      print(\"number of captions in data = %d\" % (num_in_data))\n",
    "    print(\"(total number of captions in data = %d) percent in data = %f\" % (num_in_data_total,(num_in_data_total/num_captions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_graph(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OLD_CHECKPOINT_FILE = \"trainlogSGD/model.ckpt-600000\"\n",
    "NEW_CHECKPOINT_FILE = \"trainlogSGDNEW/model.ckpt-600000\"\n",
    "\n",
    "import tensorflow as tf\n",
    "vars_to_rename = {\n",
    "    \"lstm/basic_lstm_cell/weights\": \"lstm/basic_lstm_cell/kernel\",\n",
    "    \"lstm/basic_lstm_cell/biases\": \"lstm/basic_lstm_cell/bias\",\n",
    "}\n",
    "new_checkpoint_vars = {}\n",
    "reader = tf.train.NewCheckpointReader(OLD_CHECKPOINT_FILE)\n",
    "for old_name in reader.get_variable_to_shape_map():\n",
    "  if old_name in vars_to_rename:\n",
    "    new_name = vars_to_rename[old_name]\n",
    "  else:\n",
    "    new_name = old_name\n",
    "  new_checkpoint_vars[new_name] = tf.Variable(reader.get_tensor(old_name))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(new_checkpoint_vars)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(init)\n",
    "  saver.save(sess, NEW_CHECKPOINT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
