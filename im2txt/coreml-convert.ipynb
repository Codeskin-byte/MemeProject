{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib, os, sys, zipfile\n",
    "from os.path import dirname\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.core.framework import graph_pb2\n",
    "from tensorflow.python.tools.freeze_graph import freeze_graph\n",
    "import tfcoreml\n",
    "import inference_wrapper\n",
    "import configuration\n",
    "from coremltools.proto import NeuralNetwork_pb2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = './trainlogIncNEW/model.ckpt'\n",
    "pre_frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "frozen_model_file = './frozen_model_textgenNEW.pb'\n",
    "#output_node_names = ['lstm/initial_state']\n",
    "output_node_names = ['softmax','lstm/state']\n",
    "# output_node_names = ['lstm/split']\n",
    "# original_output_node_names = ['softmax','lstm/state']\n",
    "# input_node_names = ['image_feed', 'seq_embeddings','lstm/state_feed']\n",
    "#input_node_names = ['image_feed']\n",
    "input_node_names = ['seq_embeddings','lstm/state_feed']\n",
    "beam_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "About to decide if splitting\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_2:0\", shape=(1, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_1:0' shape=(1, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_2:0' shape=(1, 512) dtype=float32>)\n",
      "About to decide if splitting\n",
      "It's splitting\n",
      "gate_inputs0 Tensor(\"lstm/basic_lstm_cell/MatMul_1:0\", shape=(1, 1, 2048), dtype=float32)\n",
      "gate_inputs1 Tensor(\"lstm/basic_lstm_cell/MatMul_2:0\", shape=(1, 1, 2048), dtype=float32)\n",
      "<tf.Variable 'lstm/basic_lstm_cell/kernel:0' shape=(812, 2048) dtype=float32_ref>\n",
      "gate_inputs Tensor(\"lstm/basic_lstm_cell/concat_2:0\", shape=(1, 2, 2048), dtype=float32)\n",
      "new_h Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "new_state LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "lstm_outputs Tensor(\"lstm/basic_lstm_cell/Mul_5:0\", shape=(1, 2, 512), dtype=float32)\n",
      "state_output LSTMStateTuple(c=<tf.Tensor 'lstm/basic_lstm_cell/Add_3:0' shape=(1, 2, 512) dtype=float32>, h=<tf.Tensor 'lstm/basic_lstm_cell/Mul_5:0' shape=(1, 2, 512) dtype=float32>)\n",
      "BUILDING DENSE\n",
      "MATMUL(TENSORDOT) w/ SPLITTING\n"
     ]
    }
   ],
   "source": [
    "# Build the inference graph.\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    model = inference_wrapper.InferenceWrapper()\n",
    "    restore_fn = model.build_graph_from_config(configuration.ModelConfig(),\n",
    "                                               checkpoint_file)\n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47081917"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the graph\n",
    "tf_model_path = './log/pre_graph_textgenNEW.pb'\n",
    "tf.train.write_graph(\n",
    "    g,\n",
    "    './log',\n",
    "    'pre_graph_textgenNEW.pb',\n",
    "    as_text=False,\n",
    ")\n",
    "\n",
    "with open(tf_model_path, 'rb') as f:\n",
    "    serialized = f.read()\n",
    "tf.reset_default_graph()\n",
    "original_gdef = tf.GraphDef()\n",
    "original_gdef.ParseFromString(serialized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.tools import strip_unused_lib\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "gdef = strip_unused_lib.strip_unused(\n",
    "        input_graph_def = original_gdef,\n",
    "        input_node_names = input_node_names,\n",
    "        output_node_names = output_node_names,\n",
    "        placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
    "# Save it to an output file\n",
    "with gfile.GFile(pre_frozen_model_file, 'wb') as f:\n",
    "    f.write(gdef.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input checkpoint './trainlogIncNEW/model.ckpt-1000000' doesn't exist!\n"
     ]
    }
   ],
   "source": [
    "# Call freeze graph\n",
    "freeze_graph(input_graph=pre_frozen_model_file,\n",
    "             input_saver='',\n",
    "             input_binary=True,\n",
    "             input_checkpoint=checkpoint_file,\n",
    "             output_node_names=','.join(output_node_names),\n",
    "             restore_op_name='save/restore_all',\n",
    "             filename_tensor_name='save/Const:0',\n",
    "             output_graph=frozen_model_file,\n",
    "             clear_devices=True,\n",
    "             initializer_nodes='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_shapes = {\n",
    "     #'image_feed:0': [299, 299, 3],\n",
    "    'seq_embeddings:0': [1, beam_size, 300],\n",
    "    'lstm/state_feed:0': [1, beam_size, 1024],\n",
    "}\n",
    "coreml_model_file = './Textgen_NEW.mlmodel'\n",
    "# output_tensor_names = ['softmax:0','lstm/state:0','lstm/initial_state:0']\n",
    "# output_tensor_names = ['lstm/initial_state:0']\n",
    "output_tensor_names = [node + ':0' for node in output_node_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes not found for 34 tensors. Executing graph to determine shapes. \n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value lstm/basic_lstm_cell/bias\n\t [[Node: lstm/basic_lstm_cell/bias/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm/basic_lstm_cell/bias)]]\n\nCaused by op u'lstm/basic_lstm_cell/bias/read', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 1008, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-42f98b5e72ba>\", line 9, in <module>\n    output_feature_names=output_tensor_names,\n  File \"/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.py\", line 552, in convert\n    custom_conversion_functions=custom_conversion_functions)\n  File \"/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.py\", line 153, in _convert_pb_to_mlmodel\n    tf.import_graph_def(gdef, name='')\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 513, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 303, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3540, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3428, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value lstm/basic_lstm_cell/bias\n\t [[Node: lstm/basic_lstm_cell/bias/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm/basic_lstm_cell/bias)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-42f98b5e72ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0minput_name_shape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#         output_feature_names=output_feature_names + ['lstm/basic_lstm_cell/MatMul_1:0'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput_feature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensor_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m#image_input_names = ['image_feed:0'],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m          \u001b[0;31m#red_bias = -1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    550\u001b[0m       \u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_probabilities_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m       \u001b[0madd_custom_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_custom_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m       custom_conversion_functions=custom_conversion_functions)\n\u001b[0m",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.pyc\u001b[0m in \u001b[0;36m_convert_pb_to_mlmodel\u001b[0;34m(tf_model_path, mlmodel_path, output_feature_names, input_name_shape_dict, image_input_names, is_bgr, red_bias, green_bias, blue_bias, gray_bias, image_scale, class_labels, predicted_feature_name, predicted_probabilities_output, add_custom_layers, custom_conversion_functions)\u001b[0m\n\u001b[1;32m    225\u001b[0m           \"Executing graph to determine shapes. \" %(len(shapes_wanted)))\n\u001b[1;32m    226\u001b[0m     \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mshapes_wanted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m     \u001b[0mtensors_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0mSHAPE_DICT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors_evaluated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value lstm/basic_lstm_cell/bias\n\t [[Node: lstm/basic_lstm_cell/bias/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm/basic_lstm_cell/bias)]]\n\nCaused by op u'lstm/basic_lstm_cell/bias/read', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 1008, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/ioloop.py\", line 759, in _run_callback\n    ret = callback()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-42f98b5e72ba>\", line 9, in <module>\n    output_feature_names=output_tensor_names,\n  File \"/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.py\", line 552, in convert\n    custom_conversion_functions=custom_conversion_functions)\n  File \"/Users/freedmand/scraps/danklearning2/tf-coreml/tfcoreml/_tf_coreml_converter.py\", line 153, in _convert_pb_to_mlmodel\n    tf.import_graph_def(gdef, name='')\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 432, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 513, in import_graph_def\n    _ProcessNewOps(graph)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 303, in _ProcessNewOps\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3540, in _add_new_tf_operations\n    for c_op in c_api_util.new_tf_operations(self)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3428, in _create_op_from_tf_operation\n    ret = Operation(c_op, self)\n  File \"/Users/freedmand/scraps/danklearning2/venv/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value lstm/basic_lstm_cell/bias\n\t [[Node: lstm/basic_lstm_cell/bias/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm/basic_lstm_cell/bias)]]\n"
     ]
    }
   ],
   "source": [
    "# Call the converter\n",
    "#output_feature_names = ['lstm/basic_lstm_cell/concat_2:0']\n",
    "\n",
    "coreml_model = tfcoreml.convert(\n",
    "        tf_model_path=frozen_model_file, \n",
    "        mlmodel_path=coreml_model_file, \n",
    "        input_name_shape_dict=input_tensor_shapes,\n",
    "#         output_feature_names=output_feature_names + ['lstm/basic_lstm_cell/MatMul_1:0'],\n",
    "        output_feature_names=output_tensor_names,\n",
    "        #image_input_names = ['image_feed:0'],\n",
    "         #red_bias = -1,\n",
    "         #green_bias = -1,\n",
    "         #blue_bias = -1,\n",
    "         #image_scale = 2.0/255.0\n",
    "#         add_custom_layers=True,\n",
    "#         custom_conversion_functions={\n",
    "#             'lstm/split': _convert_split,\n",
    "#             'lstm/basic_lstm_cell/split_1': _convert_lstmsplit,\n",
    "#             'lstm/basic_lstm_cell/split': _convert_lstmsplit,\n",
    "#         },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.uint8(np.ones([299,299,3])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "y = np.array([[[x,x]] for x in np.random.rand(300)])\n",
    "print(y[10,0,0])\n",
    "print(y[10,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "seq_embeddings = np.ones([300,1,2])*0.5 #np.array([[[x,x]] for x in np.ones(300)*0.5])\n",
    "state_feed = np.ones([1024,1,2])*0.6 #np.array([[[x,x]] for x in np.ones(1024)*0.6])\n",
    "\n",
    "#image_feed = Image.fromarray(np.uint8(np.ones([299,299,3])*100)) #np.ones([3,299,299])\n",
    "coreml_inputs = {\n",
    "    'seq_embeddings__0': seq_embeddings,\n",
    "    'lstm__state_feed__0': state_feed,\n",
    "    #'image_feed__0': image_feed,\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "# print(coreml_output['lstm__state__0'].shape)\n",
    "# print(coreml_output['softmax__0'].shape)\n",
    "# print(coreml_output['softmax__0'].reshape(38521, 1, 2))\n",
    "# print(coreml_output)\n",
    "print(coreml_output['lstm__state__0'].shape)\n",
    "#print(coreml_output['softmax__0'].shape)\n",
    "#print(coreml_output['lstm__initial_state__0'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreml_output['lstm__state__0'][0,0,10,0,0])\n",
    "print(coreml_output['lstm__state__0'][0,0,10,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreml_output['lstm__initial_state__0'][0])\n",
    "print(coreml_output['lstm__initial_state__0'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coreml_output['lstm__state__0'][:,:,:10,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_output = np.loadtxt('stateoutputTEST.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(state_output[1,:]==coreml_output['lstm__state__0'][0,0,:,0,1])[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_output[0,377])\n",
    "print(coreml_output['lstm__state__0'][0,0,377,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.moveaxis(np.asarray(image) / 256.0, [0, 1, 2], [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 'image_feed:0': [299, 299, 3],\n",
    "    'seq_embeddings:0': [1, 1, 300],\n",
    "    'lstm/state_feed:0': [1, 1024],\n",
    "\"\"\"\n",
    "coreml_inputs = {\n",
    "    'image_feed__0': image,\n",
    "#     'seq_embeddings__0': np.random.rand(300, 1, 1),\n",
    "#     'lstm__state_feed__0': np.random.rand(1024),\n",
    "}\n",
    "coreml_output = coreml_model.predict(coreml_inputs, useCPUOnly=True)\n",
    "print(list(coreml_output['lstm__initial_state__0'][:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1000px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(gdef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_bytes = embeddings.flatten().tobytes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open('embeddings_bin.bin', 'wb').write(embeddings_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "read_model = coremltools.models.MLModel(coreml_model_file)\n",
    "dir(read_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coremltools\n",
    "def print_coreml_nn_layer_info(spec):\n",
    "    nn_layers = coremltools.models.utils._get_nn_layers(spec)\n",
    "    for i, layer in enumerate(nn_layers):\n",
    "        if layer.WhichOneof('layer') == 'custom':\n",
    "            print 'layer_id = ', i\n",
    "            print layer\n",
    "        else:\n",
    "            print('{}: layer type: ({}) , inputs: {}, outputs: {}'.\n",
    "              format(i,layer.WhichOneof('layer'), \", \".join([x for x in layer.input]), \", \".join([x for x in layer.output])))\n",
    "\n",
    "print_coreml_nn_layer_info(coreml_model.get_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model!!!\n",
    "\n",
    "import PIL\n",
    "from IPython.core.display import Image\n",
    "\n",
    "filename = '/Users/freedmand/Desktop/zelda_driving.jpg'\n",
    "with tf.gfile.GFile(filename, \"rb\") as f:\n",
    "  image = PIL.Image.open(f)\n",
    "  image = image.resize([299,299], PIL.Image.ANTIALIAS)\n",
    "    \n",
    "display(Image(filename, width=299, height=299))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
